{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter4 - Alice in Wonderland analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as b\n",
    "from spacy.lang.en import English\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xml.etree.ElementTree import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ohjeita: \n",
    "- [x] Poista kirjan alusta ja lopusta The Project Gutenberg -sivuston lisäämät otsikot ja huomautukset.\n",
    "\n",
    "Kysymykset:\n",
    "- [x] **Kuinka monta tokenia** \"en_core_web_lg\" -pipeline löytää dokumentista? Entä kuinka monta näistä on **\"stop word\"** tokenia?\n",
    "- [x] Kuinka monta **henkilö tokenia** (PERSON) \"en_core_web_lg\" -pipeline löytää kirjasta? (Eli kuinka monta kertaa kirjassa mainitaan joku henkilö.)\n",
    "- [x] Kuinka monta kertaa näistä mainitaan **Alice**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktio, joka hakee parametriksi annettusta osotteesta tekstin\n",
    "def alice_text(url):\n",
    "    r = requests.get(url)\n",
    "    soup = b(r.content, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    # Korvataan \\n ja \\r merkinnät tyhjällä\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = alice_text(\"http://www.gutenberg.org/files/11/11-h/11-h.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ennen large-paketin käyttöä pitää ajaa terminaalissa komento:\n",
    "`python -m spacy download en_core_lg` tai python-cellissä `!python -m spacy download en_core_lg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsitaan sivulta ylimääräiset tekstit pois\n",
    "Jätetään pelkkä kirjan osuus. Tämä on hieman kömpelö tapa, mutta toimiva eikä tässä kovin kauaa minulla mennyt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alku (\"Alice was beginning...\")\n",
    "doc[729]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "END"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loppu (\"THE END\")\n",
    "doc[-3631]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Määritetää dokumentti uudella alulla ja lopulla\n",
    "doc = doc[729:-3630]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 37241\n",
      "Stop Words: 16939\n",
      "Stop wordeja 45.48% kaikista tokeneista.\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens:\",len(doc))\n",
    "print(\"Stop Words:\",len([token.text for token in doc if token.is_stop]))\n",
    "print(f\"Stop wordeja {(len([token.text for token in doc if token.is_stop])/len(doc))*100:.2f}% kaikista tokeneista.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Henkilöt tekstissä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henkilöitä löytyi 575 kappaletta.\n"
     ]
    }
   ],
   "source": [
    "# Kuinka monta henkilöä \"en_core_web_lg\" -pipeline löytää\n",
    "persons = [ent.text for ent in doc.ents if ent.label_ == 'PERSON']\n",
    "print(\"Henkilöitä löytyi\",len(persons),\"kappaletta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Dinah’ll', 'Alice  ', 'Alice', 'Alice', 'Alice  ', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice  ', 'Alice  ', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Mabel', 'Alice', 'Mabel  ', 'I’m Mabel', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'William', 'Alice', 'Où  est ma', 'Alice', 'Alice', 'Alice', 'Alice', 'Mouse', 'Mouse', 'Alice', 'Mouse', 'Alice', 'Alice', 'Mouse', 'Mouse', 'Mouse', 'Alice', 'Lory', 'Eaglet', 'Alice', 'Alice', 'Alice', 'Mouse', 'Alice', 'Edwin', 'Mercia  ', 'Mouse', 'Lory', 'Mouse', 'Mouse', 'Edgar Atheling', 'William', 'Alice', 'Alice', 'Eaglet', 'Eaglet', 'Alice', 'Shakespeare', 'Alice', 'Alice', 'Mouse', 'Alice', 'Alice', 'Alice', 'Mouse', 'Alice', 'Alice', 'Alice', 'Mouse', 'Fury', 'Mouse', 'Alice', 'Alice', 'Alice', 'Alice', 'Mouse', 'Alice', 'Alice', 'Alice', 'Dinah', 'Alice', 'Alice', 'Mouse', 'Alice', 'Alice', 'Mary Ann', 'Alice', '’d  ', 'Mary Ann', 'Alice', 'Dinah’ll', 'Alice', 'Alice  ', 'Alice', 'Alice', 'Alice', 'Alice', 'Mary Ann', 'Mary Ann', 'Alice  ', 'Alice', 'Alice', 'Alice', 'Pat', 'Pat', 'Alice', 'Alice', 'Bill', 'Bill', 'Bill', 'Bill', 'Bill', 'Bill', 'Bill', 'Bill', 'Brandy', 'Alice', 'Jack', 'Dinah  ', 'Alice', 'Alice', 'Alice', 'Lizard', 'Bill', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', '’d  ', 'Alice', 'CHAPTER V.  Advice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'William', 'Alice', 'William', 'William', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Footman', 'Alice', 'Alice', 'Footman', 'Alice', 'Alice  ', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Cheshire Puss', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Hatter', 'Hatter', 'Alice', 'Alice  ', 'Alice', 'Alice  ', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Alice', 'Alice', 'Hatter', 'Dormouse', 'Hatter', 'Alice  ', 'Hatter', 'Alice', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Hatter', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Hatter', 'Alice', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Alice  ', 'Alice', 'Alice', 'Hatter', 'Dormouse', 'Elsie', 'Alice', 'Dormouse', 'Alice', 'Dormouse', 'Alice', 'Alice', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Alice', 'Dormouse', '’d', 'Alice', 'Dormouse', 'Alice', 'Dormouse', 'Hatter', 'Dormouse', 'Alice', 'Hatter', 'Alice', 'Alice', 'Hatter', 'Alice', 'Dormouse', 'Alice', 'Alice', 'Alice', 'Dormouse', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice  ', 'Alice  ', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice  ', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Queen', 'Alice', 'Alice', 'Alice', 'Queen', 'Alice', '’d', 'The Mock Turtle’s Story', 'Alice', 'I’m a Duchess', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Queen', 'Alice', 'Alice', 'the Mock Turtle', 'Alice', 'Mock Turtle Soup', 'Alice', 'Alice', 'Gryphon', 'Alice', 'Gryphon', 'Alice', 'Alice', 'Alice', 'Alice', 'the Mock Turtle', 'Alice', 'the Mock Turtle', 'the Mock Turtle', 'Alice', 'Alice  ', 'Alice', 'Alice', 'the Mock Turtle', 'Alice', 'The Mock Turtle', 'Alice', 'the Mock Turtle', 'Alice', 'the Mock Turtle', 'Alice', 'Alice', 'the Mock Turtle', 'Alice', 'Alice', 'Alice', 'Alice', 'the Mock Turtle', 'Alice', 'Gryphon', 'Gryphon', 'Alice', 'the Mock Turtle', 'Alice', 'Alice', 'the Mock Turtle', 'Alice', 'The Mock Turtle', 'Alice', 'the Mock Turtle', 'Alice', 'Alice', 'Gryphon', 'Gryphon', 'Gryphon', 'Gryphon', 'the Mock Turtle', 'Gryphon', 'Alice', 'Alice', 'the Mock Turtle', 'Alice', 'the Mock Turtle', 'Alice', 'the Mock Turtle', 'the Mock Turtle', 'Alice', 'Dinn', 'the Mock Turtle', 'Alice', 'the Mock Turtle', 'the Mock Turtle', 'Gryphon', 'Alice', 'Alice', 'Alice', 'Alice', 'Gryphon', 'Alice', 'Alice', 'Alice', 'the Mock Turtle', 'Alice', 'Alice', 'the Mock Turtle', 'Alice', 'William', 'Gryphon', 'Alice', 'Gryphon', 'Alice', 'Gryphon', 'the Mock Turtle', 'Alice', 'the Mock Turtle', 'Gryphon', 'Alice', 'Alice', 'Panther', 'Panther', '’d', 'Gryphon', 'the Mock Turtle', 'the Mock Turtle', 'Alice  replied', 'Beau', 'Beau', 'Beau', 'Beau', 'Gryphon', 'the Mock Turtle', 'Gryphon', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Bill', 'Hatter', 'Hatter', 'Dormouse', 'Dormouse', 'Hatter', 'Hatter', 'Hatter', 'Hatter', 'Alice', 'Dormouse', 'Alice', 'Dormouse', 'Alice', 'Dormouse', 'Hatter', 'Hatter', 'Hatter', 'Hatter', 'Hatter', 'Dormouse', 'Hatter', 'Hatter', 'Hatter', 'Alice', 'Hatter', 'Alice', 'Hatter', 'Hatter', 'Hatter', 'Alice', 'Dormouse', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Bill', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice', 'Alice  ', 'Alice', 'Alice', 'Mock Turtle', 'Queen']\n"
     ]
    }
   ],
   "source": [
    "# Kuinka monta kertaa näistä mainitaan Alice?\n",
    "print(persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice löytyi 376 kertaa.\n",
      "Aliceita 65.39% kaikista tekstin henkilöistä.\n"
     ]
    }
   ],
   "source": [
    "# TAPA 1 - tavalliset listakikat\n",
    "alices = []\n",
    "for alice in persons:\n",
    "    if alice == 'Alice':\n",
    "        alices.append(alice)\n",
    "    if alice == 'Alice  ':\n",
    "        alices.append(alice)\n",
    "print(\"Alice löytyi\",len(alices),\"kertaa.\")\n",
    "print(f\"Aliceita {(len(alices)/len(persons))*100:.2f}% kaikista tekstin henkilöistä.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice löytyi: 396 kertaa.\n"
     ]
    }
   ],
   "source": [
    "# TAPA 2 - hyödynnetään spacya, koska kyse on kuitenkin nlp:stä\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [[{\"LOWER\": \"alice\"}]]\n",
    "\n",
    "matcher.add(\"ALICE\", pattern)\n",
    "matches = matcher(doc)\n",
    "print(\"Alice löytyi:\", len(matches),\"kertaa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jälkimmäisellä tavalla löytyi parisenkymmentä Alicea enemmän."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
