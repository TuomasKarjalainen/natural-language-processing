{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NLP From Scratch: Translation with a Sequence to Sequence Network and Attention\n",
    "*******************************************************************************\n",
    "**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n",
    "\n",
    "This is the third and final tutorial on doing \"NLP From Scratch\", where we\n",
    "write our own classes and functions to preprocess the data to do our NLP\n",
    "modeling tasks. We hope after you complete this tutorial that you'll proceed to\n",
    "learn how `torchtext` can handle much of this preprocessing for you in the\n",
    "three tutorials immediately following this one.\n",
    "\n",
    "In this project we will be teaching a neural network to translate from\n",
    "French to English.\n",
    "\n",
    "::\n",
    "\n",
    "    [KEY: > input, = target, < output]\n",
    "\n",
    "    > il est en train de peindre un tableau .\n",
    "    = he is painting a picture .\n",
    "    < he is painting a picture .\n",
    "\n",
    "    > pourquoi ne pas essayer ce vin delicieux ?\n",
    "    = why not try that delicious wine ?\n",
    "    < why not try that delicious wine ?\n",
    "\n",
    "    > elle n est pas poete mais romanciere .\n",
    "    = she is not a poet but a novelist .\n",
    "    < she not not a poet but a novelist .\n",
    "\n",
    "    > vous etes trop maigre .\n",
    "    = you re too skinny .\n",
    "    < you re all alone .\n",
    "\n",
    "... to varying degrees of success.\n",
    "\n",
    "This is made possible by the simple but powerful idea of the `sequence\n",
    "to sequence network <https://arxiv.org/abs/1409.3215>`__, in which two\n",
    "recurrent neural networks work together to transform one sequence to\n",
    "another. An encoder network condenses an input sequence into a vector,\n",
    "and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
    "   :alt:\n",
    "\n",
    "To improve upon this model we'll use an `attention\n",
    "mechanism <https://arxiv.org/abs/1409.0473>`__, which lets the decoder\n",
    "learn to focus over a specific range of the input sequence.\n",
    "\n",
    "**Recommended Reading:**\n",
    "\n",
    "I assume you have at least installed PyTorch, know Python, and\n",
    "understand Tensors:\n",
    "\n",
    "-  https://pytorch.org/ For installation instructions\n",
    "-  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general\n",
    "-  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview\n",
    "-  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user\n",
    "\n",
    "\n",
    "It would also be useful to know about Sequence to Sequence networks and\n",
    "how they work:\n",
    "\n",
    "-  `Learning Phrase Representations using RNN Encoder-Decoder for\n",
    "   Statistical Machine Translation <https://arxiv.org/abs/1406.1078>`__\n",
    "-  `Sequence to Sequence Learning with Neural\n",
    "   Networks <https://arxiv.org/abs/1409.3215>`__\n",
    "-  `Neural Machine Translation by Jointly Learning to Align and\n",
    "   Translate <https://arxiv.org/abs/1409.0473>`__\n",
    "-  `A Neural Conversational Model <https://arxiv.org/abs/1506.05869>`__\n",
    "\n",
    "You will also find the previous tutorials on\n",
    ":doc:`/intermediate/char_rnn_classification_tutorial`\n",
    "and :doc:`/intermediate/char_rnn_generation_tutorial`\n",
    "helpful as those concepts are very similar to the Encoder and Decoder\n",
    "models, respectively.\n",
    "\n",
    "And for more, read the papers that introduced these topics:\n",
    "\n",
    "-  `Learning Phrase Representations using RNN Encoder-Decoder for\n",
    "   Statistical Machine Translation <https://arxiv.org/abs/1406.1078>`__\n",
    "-  `Sequence to Sequence Learning with Neural\n",
    "   Networks <https://arxiv.org/abs/1409.3215>`__\n",
    "-  `Neural Machine Translation by Jointly Learning to Align and\n",
    "   Translate <https://arxiv.org/abs/1409.0473>`__\n",
    "-  `A Neural Conversational Model <https://arxiv.org/abs/1506.05869>`__\n",
    "\n",
    "\n",
    "**Requirements**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data files\n",
    "==================\n",
    "\n",
    "The data for this project is a set of many thousands of English to\n",
    "French translation pairs.\n",
    "\n",
    "`This question on Open Data Stack\n",
    "Exchange <https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages>`__\n",
    "pointed me to the open translation site https://tatoeba.org/ which has\n",
    "downloads available at https://tatoeba.org/eng/downloads - and better\n",
    "yet, someone did the extra work of splitting language pairs into\n",
    "individual text files here: https://www.manythings.org/anki/\n",
    "\n",
    "The English to French pairs are too big to include in the repo, so\n",
    "download to ``data/eng-fra.txt`` before continuing. The file is a tab\n",
    "separated list of translation pairs:\n",
    "\n",
    "::\n",
    "\n",
    "    I am cold.    J'ai froid.\n",
    "\n",
    ".. Note::\n",
    "   Download the data from\n",
    "   `here <https://download.pytorch.org/tutorial/data.zip>`_\n",
    "   and extract it to the current directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the character encoding used in the character-level RNN\n",
    "tutorials, we will be representing each word in a language as a one-hot\n",
    "vector, or giant vector of zeros except for a single one (at the index\n",
    "of the word). Compared to the dozens of characters that might exist in a\n",
    "language, there are many many more words, so the encoding vector is much\n",
    "larger. We will however cheat a bit and trim the data to only use a few\n",
    "thousand words per language.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/word-encoding.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a unique index per word to use as the inputs and targets of\n",
    "the networks later. To keep track of all this we will use a helper class\n",
    "called ``Lang`` which has word → index (``word2index``) and index → word\n",
    "(``index2word``) dictionaries, as well as a count of each word\n",
    "``word2count`` to use to later replace rare words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suomi-englanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Mene.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Moro!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Terve.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Juokse!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Juoskaa!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1                                                  2\n",
       "0   Go.     Mene.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "1   Hi.     Moro!  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
       "2   Hi.    Terve.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
       "3  Run!   Juokse!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "4  Run!  Juoskaa!  CC-BY 2.0 (France) Attribution: tatoeba.org #9..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_engfin = pd.read_csv('eng-fin.txt', delimiter = \"\\t\", header=None)\n",
    "df_engfin.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Mene.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Moro!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Terve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Juokse!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Juoskaa!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1\n",
       "0   Go.     Mene.\n",
       "1   Hi.     Moro!\n",
       "2   Hi.    Terve.\n",
       "3  Run!   Juokse!\n",
       "4  Run!  Juoskaa!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_engfin = df_engfin.drop(columns=[2])\n",
    "df_engfin.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_engfin.to_numpy()\n",
    "np.savetxt(\"./data/eng-fin2.txt\", text, fmt = \"%s\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files are all in Unicode, to simplify we will turn Unicode\n",
    "characters to ASCII, make everything lowercase, and trim most\n",
    "punctuation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split\n",
    "lines into pairs. The files are all English → Other Language, so if we\n",
    "want to translate from Other Language → English I added the ``reverse``\n",
    "flag to reverse the pairs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are a *lot* of example sentences and we want to train\n",
    "something quickly, we'll trim the data set to only relatively short and\n",
    "simple sentences. Here the maximum length is 10 words (that includes\n",
    "ending punctuation) and we're filtering to sentences that translate to\n",
    "the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\n",
    "earlier).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "-  Read text file and split into lines, split lines into pairs\n",
    "-  Normalize text, filter by length and content\n",
    "-  Make word lists from sentences in pairs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 63562 sentence pairs\n",
      "Trimmed to 4385 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fin2 3241\n",
      "eng 1747\n",
      "['sina sarjet sydameni .', 'you re breaking my heart .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fin2', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Seq2Seq Model\n",
    "=================\n",
    "\n",
    "A Recurrent Neural Network, or RNN, is a network that operates on a\n",
    "sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "A `Sequence to Sequence network <https://arxiv.org/abs/1409.3215>`__, or\n",
    "seq2seq network, or `Encoder Decoder\n",
    "network <https://arxiv.org/pdf/1406.1078v3.pdf>`__, is a model\n",
    "consisting of two RNNs called the encoder and decoder. The encoder reads\n",
    "an input sequence and outputs a single vector, and the decoder reads\n",
    "that vector to produce an output sequence.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
    "   :alt:\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input\n",
    "corresponds to an output, the seq2seq model frees us from sequence\n",
    "length and order, which makes it ideal for translation between two\n",
    "languages.\n",
    "\n",
    "Consider the sentence \"Je ne suis pas le chat noir\" → \"I am not the\n",
    "black cat\". Most of the words in the input sentence have a direct\n",
    "translation in the output sentence, but are in slightly different\n",
    "orders, e.g. \"chat noir\" and \"black cat\". Because of the \"ne/pas\"\n",
    "construction there is also one more word in the input sentence. It would\n",
    "be difficult to produce a correct translation directly from the sequence\n",
    "of input words.\n",
    "\n",
    "With a seq2seq model the encoder creates a single vector which, in the\n",
    "ideal case, encodes the \"meaning\" of the input sequence into a single\n",
    "vector — a single point in some N dimensional space of sentences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Encoder\n",
    "-----------\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for\n",
    "every word from the input sentence. For every input word the encoder\n",
    "outputs a vector and a hidden state, and uses the hidden state for the\n",
    "next input word.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/encoder-network.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decoder\n",
    "-----------\n",
    "\n",
    "The decoder is another RNN that takes the encoder output vector(s) and\n",
    "outputs a sequence of words to create the translation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Decoder\n",
    "^^^^^^^^^^^^^^\n",
    "\n",
    "In the simplest seq2seq decoder we use only last output of the encoder.\n",
    "This last output is sometimes called the *context vector* as it encodes\n",
    "context from the entire sequence. This context vector is used as the\n",
    "initial hidden state of the decoder.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and\n",
    "hidden state. The initial input token is the start-of-string ``<SOS>``\n",
    "token, and the first hidden state is the context vector (the encoder's\n",
    "last hidden state).\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/decoder-network.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I encourage you to train and observe the results of this model, but to\n",
    "save space we'll be going straight for the gold and introducing the\n",
    "Attention Mechanism.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Decoder\n",
    "^^^^^^^^^^^^^^^^^\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder,\n",
    "that single vector carries the burden of encoding the entire sentence.\n",
    "\n",
    "Attention allows the decoder network to \"focus\" on a different part of\n",
    "the encoder's outputs for every step of the decoder's own outputs. First\n",
    "we calculate a set of *attention weights*. These will be multiplied by\n",
    "the encoder output vectors to create a weighted combination. The result\n",
    "(called ``attn_applied`` in the code) should contain information about\n",
    "that specific part of the input sequence, and thus help the decoder\n",
    "choose the right output words.\n",
    "\n",
    ".. figure:: https://i.imgur.com/1152PYf.png\n",
    "   :alt:\n",
    "\n",
    "Calculating the attention weights is done with another feed-forward\n",
    "layer ``attn``, using the decoder's input and hidden state as inputs.\n",
    "Because there are sentences of all sizes in the training data, to\n",
    "actually create and train this layer we have to choose a maximum\n",
    "sentence length (input length, for encoder outputs) that it can apply\n",
    "to. Sentences of the maximum length will use all the attention weights,\n",
    "while shorter sentences will only use the first few.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/attention-decoder-network.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n",
    "  limitation by using a relative position approach. Read about \"local\n",
    "  attention\" in `Effective Approaches to Attention-based Neural Machine\n",
    "  Translation <https://arxiv.org/abs/1508.04025>`__.</p></div>\n",
    "\n",
    "Training\n",
    "========\n",
    "\n",
    "Preparing Training Data\n",
    "-----------------------\n",
    "\n",
    "To train, for each pair we will need an input tensor (indexes of the\n",
    "words in the input sentence) and target tensor (indexes of the words in\n",
    "the target sentence). While creating these vectors we will append the\n",
    "EOS token to both sequences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model\n",
    "------------------\n",
    "\n",
    "To train we run the input sentence through the encoder, and keep track\n",
    "of every output and the latest hidden state. Then the decoder is given\n",
    "the ``<SOS>`` token as its first input, and the last hidden state of the\n",
    "encoder as its first hidden state.\n",
    "\n",
    "\"Teacher forcing\" is the concept of using the real target outputs as\n",
    "each next input, instead of using the decoder's guess as the next input.\n",
    "Using teacher forcing causes it to converge faster but `when the trained\n",
    "network is exploited, it may exhibit\n",
    "instability <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf>`__.\n",
    "\n",
    "You can observe outputs of teacher-forced networks that read with\n",
    "coherent grammar but wander far from the correct translation -\n",
    "intuitively it has learned to represent the output grammar and can \"pick\n",
    "up\" the meaning once the teacher tells it the first few words, but it\n",
    "has not properly learned how to create the sentence from the translation\n",
    "in the first place.\n",
    "\n",
    "Because of the freedom PyTorch's autograd gives us, we can randomly\n",
    "choose to use teacher forcing or not with a simple if statement. Turn\n",
    "``teacher_forcing_ratio`` up to use more of it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to print time elapsed and estimated time\n",
    "remaining given the current time and progress %.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "-  Start a timer\n",
    "-  Initialize optimizers and criterion\n",
    "-  Create set of training pairs\n",
    "-  Start empty losses array for plotting\n",
    "\n",
    "Then we call ``train`` many times and occasionally print the progress (%\n",
    "of examples, time so far, estimated time) and average loss.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "            \n",
    "            accuracy, sentences =  bag_of_words_accuracy(encoder1, attn_decoder1)\n",
    "            print(f\"{sentences} lauseen Bag-Of-Words tarkkuus: {accuracy}%\")\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words** -menetelmässä analysoidaan sanojen ominaisuuksien keskiarvoa/summaa. Eli menetelmässä ei ole mitään väliä sanojen järjestyksellä. Esimerkki Bag of Words menetelmästä on **Bayesin naivi luokitin**, jota käytetään mm. späm sähköpostien tunnistamiseen.\n",
    "https://medium.com/analytics-vidhya/naive-bayes-classifier-for-text-classification-556fabaf252b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_accuracy(encoder, decoder, sentences=500):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "    import pandas as pd\n",
    "    sentences=sentences\n",
    "    preds = 0\n",
    "    words = 0\n",
    "    for i in range(sentences):\n",
    "        pair = random.choice(pairs)\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        \n",
    "        count_vec = CountVectorizer()\n",
    "        count_data = count_vec.fit_transform([pair[1],output_sentence])\n",
    "        count_df = pd.DataFrame(count_data.toarray(), columns=count_vec.get_feature_names())\n",
    "        \n",
    "        values = count_df.mul(count_df.iloc[0]).sum(axis=1).values\n",
    "        words += values[0]\n",
    "        preds += values[1]\n",
    "        accuracy = round((preds/words)*100,5)        \n",
    "\n",
    "    return accuracy, sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KESKENERÄISET BLEU SCORE KOKEILUT..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_accuracy(encoder, decoder, sentences=500):\n",
    "    from nltk.translate.bleu_score import corpus_bleu\n",
    "    sentences=sentences\n",
    "    list_of_references = []\n",
    "    hypotheses = []\n",
    "    preds = 0\n",
    "    words = 0\n",
    "    for i in range(sentences):\n",
    "        pair = random.choice(pairs)\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        list_of_references.append(output_sentence)\n",
    "        hypotheses.append(pair[1])\n",
    "        weights = (1.0/1.0, )\n",
    "        accuracy = corpus_bleu(ref, hyp, weights)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (10):\n",
    "#     accuracy = bleu_accuracy(encoder1, attn_decoder1, sentences=200)\n",
    "#     print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# list_of_references = []\n",
    "# hypotheses = []\n",
    "# preds = 0\n",
    "# words = 0\n",
    "# for i in range(10):\n",
    "#     pair = random.choice(pairs)\n",
    "#     output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "#     output_sentence = ' '.join(output_words)\n",
    "#     list_of_references.append(output_sentence)\n",
    "#     hypotheses.append(pair[1])\n",
    "#     weights = (1.0/1.0, )\n",
    "#     accuracy = corpus_bleu(ref, hyp, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'm', 'very', 'happy', 'for', 'you', '.']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "reference = ['i m very happy for you .'.split(),]\n",
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score -> 8.44484326442819e-78\n",
      "Individual 1-gram: 0.857143\n",
      "Individual 2-gram: 0.666667\n",
      "Individual 3-gram: 0.400000\n",
      "Individual 4-gram: 0.000000\n"
     ]
    }
   ],
   "source": [
    "candidate = 'i m very sad for you .'.split()\n",
    "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))\n",
    "print('Individual 1-gram: %f' % sentence_bleu(reference, candidate, weights=(1, 0, 0, 0)))\n",
    "print('Individual 2-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 1, 0, 0)))\n",
    "print('Individual 3-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 1, 0)))\n",
    "print('Individual 4-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_accuracy_new(encoder, decoder, sentences=500):\n",
    "    from nltk.translate.bleu_score import sentence_bleu\n",
    "    sentences=sentences\n",
    "    list_of_references = []\n",
    "    candidates = []\n",
    "    for i in range(sentences):\n",
    "        pair = random.choice(pairs)\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        \n",
    "        reference = [pair[1].split(),]\n",
    "        list_of_references.append(reference)\n",
    "        \n",
    "        candidate = output_sentence.split()\n",
    "        candidates.append(candidate)\n",
    " \n",
    "        print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))\n",
    "\n",
    "    return accuracy, list_of_references, hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'm', 'not', 'sure', '.', '<EOS>']\n",
      "[['i', 'm', 'not', 'my', 'father', '.']]\n",
      "BLEU score -> 6.206021746903507e-78\n",
      "\n",
      "Individual 1-gram: 0.666667\n",
      "Individual 2-gram: 0.400000\n",
      "Individual 3-gram: 0.250000\n",
      "Individual 4-gram: 0.000000\n",
      "\n",
      "['i', 'm', 'a', '.', '.', '<EOS>']\n",
      "[['i', 'm', 'fair', '.']]\n",
      "BLEU score -> 8.38826642100846e-155\n",
      "\n",
      "Individual 1-gram: 0.500000\n",
      "Individual 2-gram: 0.200000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "\n",
      "['she', 'is', 'a', '.', '.', '<EOS>']\n",
      "[['he', 'is', 'a', 'poet', '.']]\n",
      "BLEU score -> 8.38826642100846e-155\n",
      "\n",
      "Individual 1-gram: 0.500000\n",
      "Individual 2-gram: 0.200000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "\n",
      "['you', 're', 'still', 'green', '.', '<EOS>']\n",
      "[['you', 'aren', 't', 'helping', '.']]\n",
      "BLEU score -> 1.384292958842266e-231\n",
      "\n",
      "Individual 1-gram: 0.333333\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "\n",
      "['i', 'm', 'a', 'little', '.', '.', '<EOS>']\n",
      "[['i', 'm', 'in', 'the', 'shower', '.']]\n",
      "BLEU score -> 7.711523862191631e-155\n",
      "\n",
      "Individual 1-gram: 0.428571\n",
      "Individual 2-gram: 0.166667\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "list_of_references = []\n",
    "candidates = []\n",
    "for i in range(5):\n",
    "    encoder = encoder1\n",
    "    decoder = attn_decoder1\n",
    "    pair = random.choice(pairs)\n",
    "    output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    reference = [pair[1].split(),]\n",
    "    list_of_references.append(reference)\n",
    "    \n",
    "    candidate = output_sentence.split()\n",
    "    candidates.append(candidate)\n",
    "\n",
    "    print(candidate)\n",
    "    print(reference)\n",
    "    print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))\n",
    "    print()\n",
    "    print('Individual 1-gram: %f' % sentence_bleu(reference, candidate, weights=(1, 0, 0, 0)))\n",
    "    print('Individual 2-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 1, 0, 0)))\n",
    "    print('Individual 3-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 1, 0)))\n",
    "    print('Individual 4-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 0, 1)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = random.choice(pairs)\n",
    "output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "output_sentence = ' '.join(output_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i m alone .'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'm', 'alone', '.']]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pair[1].split(),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['firmly',\n",
       " 'girl',\n",
       " 'girl',\n",
       " 'girl',\n",
       " 'girl',\n",
       " 'girl',\n",
       " 'girl',\n",
       " 'girl',\n",
       " 'roof',\n",
       " 'intelligent']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['firmly',\n",
       "  'girl',\n",
       "  'girl',\n",
       "  'girl',\n",
       "  'girl',\n",
       "  'girl',\n",
       "  'girl',\n",
       "  'girl',\n",
       "  'roof',\n",
       "  'intelligent']]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = [output_sentence.split(),]\n",
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.44484326442819e-78\n"
     ]
    }
   ],
   "source": [
    "score = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bleu_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-23da76f0b565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bleu_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    accuracy = bleu_accuracy(encoder1, attn_decoder1, sentences=10)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "weights = (1.0/1.0, )\n",
    "ref =  [['I', 'gay', 'girls']]\n",
    "hyp =  [['I', 'like', 'girls']]\n",
    "# corpus_bleu(pair[0], pair[1], weights)\n",
    "corpus_bleu(ref, hyp, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'like', 'cars']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'olet puhelias .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'friendly biggest first first optimists wrong options college cookies cookies'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['friendly',\n",
       " 'biggest',\n",
       " 'first',\n",
       " 'first',\n",
       " 'optimists',\n",
       " 'wrong',\n",
       " 'options',\n",
       " 'college',\n",
       " 'cookies',\n",
       " 'cookies']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds = []\n",
    "\n",
    "for i in output_words:\n",
    "    testpreds.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['friendly',\n",
       " 'biggest',\n",
       " 'first',\n",
       " 'first',\n",
       " 'optimists',\n",
       " 'wrong',\n",
       " 'options',\n",
       " 'college',\n",
       " 'cookies',\n",
       " 'cookies']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.38516\n",
      "29.73958\n",
      "29.62398\n",
      "29.46336\n",
      "28.32399\n",
      "28.36842\n",
      "28.28877\n",
      "29.54899\n",
      "29.51745\n",
      "30.16615\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    accuracy = bag_of_words(encoder1, attn_decoder1)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> olet puhelias .\n",
      "= you re talkative .\n",
      "< friendly biggest first first optimists wrong options college cookies cookies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "encoder = encoder1\n",
    "decoder = attn_decoder1\n",
    "pair = random.choice(pairs)\n",
    "print('>', pair[0])\n",
    "print('=', pair[1])\n",
    "output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "output_sentence = ' '.join(output_words) \n",
    "print('<', output_sentence)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1,1))\n",
    "count_data = count_vec.fit_transform([pair[1]])\n",
    "count_df = pd.DataFrame(count_data.toarray(), columns=count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loser</th>\n",
       "      <th>re</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loser  re  you\n",
       "0      1   1    1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1,1))\n",
    "count_data = count_vec.fit_transform([output_sentence])\n",
    "count_df = pd.DataFrame(count_data.toarray(), columns=count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eos</th>\n",
       "      <th>re</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eos  re  you\n",
       "0    1   1    1"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eos      0\n",
       "loser    1\n",
       "re       1\n",
       "you      1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dataframe.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he s a . . <EOS>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he s a journalist .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "CountVec = CountVectorizer(ngram_range=(1,1))\n",
    "Count_data = CountVec.fit_transform(output_words,pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cv_dataframe=pd.DataFrame(Count_data.toarray(),columns=CountVec.get_feature_names())\n",
    "cv_dataframe = (cv_dataframe > 0).astype(int)\n",
    "\n",
    "values = cv_dataframe.mul(cv_dataframe.iloc[0]).sum(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_decoder1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting results\n",
    "----------------\n",
    "\n",
    "Plotting is done with matplotlib, using the array of loss values\n",
    "``plot_losses`` saved while training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "==========\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets so\n",
    "we simply feed the decoder's predictions back to itself for each step.\n",
    "Every time it predicts a word we add it to the output string, and if it\n",
    "predicts the EOS token we stop there. We also store the decoder's\n",
    "attention outputs for display later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate random sentences from the training set and print out the\n",
    "input, target, and output to make some subjective quality judgements:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Evaluating\n",
    "=======================\n",
    "\n",
    "With all these helper functions in place (it looks like extra work, but\n",
    "it makes it easier to run multiple experiments) we can actually\n",
    "initialize a network and start training.\n",
    "\n",
    "Remember that the input sentences were heavily filtered. For this small\n",
    "dataset we can use relatively small networks of 256 hidden nodes and a\n",
    "single GRU layer. After about 40 minutes on a MacBook CPU we'll get some\n",
    "reasonable results.\n",
    "\n",
    ".. Note::\n",
    "   If you run this notebook you can train, interrupt the kernel,\n",
    "   evaluate, and continue training later. Comment out the lines where the\n",
    "   encoder and decoder are initialized and run ``trainIters`` again.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 17s (- 5m 31s) (500 5%) 3.5112\n",
      "500 lauseen Bag-Of-Words tarkkuus: 14.70588%\n",
      "0m 39s (- 5m 57s) (1000 10%) 3.1563\n",
      "500 lauseen Bag-Of-Words tarkkuus: 6.04982%\n",
      "1m 3s (- 5m 58s) (1500 15%) 2.9870\n",
      "500 lauseen Bag-Of-Words tarkkuus: 19.23077%\n",
      "1m 27s (- 5m 50s) (2000 20%) 2.9190\n",
      "500 lauseen Bag-Of-Words tarkkuus: 17.18282%\n",
      "1m 51s (- 5m 33s) (2500 25%) 2.7331\n",
      "500 lauseen Bag-Of-Words tarkkuus: 27.02179%\n",
      "2m 14s (- 5m 13s) (3000 30%) 2.7726\n",
      "500 lauseen Bag-Of-Words tarkkuus: 22.66187%\n",
      "2m 37s (- 4m 53s) (3500 35%) 2.5919\n",
      "500 lauseen Bag-Of-Words tarkkuus: 22.98554%\n",
      "3m 1s (- 4m 31s) (4000 40%) 2.5914\n",
      "500 lauseen Bag-Of-Words tarkkuus: 26.17722%\n",
      "3m 24s (- 4m 10s) (4500 45%) 2.5984\n",
      "500 lauseen Bag-Of-Words tarkkuus: 25.29382%\n",
      "3m 47s (- 3m 47s) (5000 50%) 2.4236\n",
      "500 lauseen Bag-Of-Words tarkkuus: 31.74447%\n",
      "4m 11s (- 3m 25s) (5500 55%) 2.4131\n",
      "500 lauseen Bag-Of-Words tarkkuus: 30.858%\n",
      "4m 34s (- 3m 3s) (6000 60%) 2.4341\n",
      "500 lauseen Bag-Of-Words tarkkuus: 25.93703%\n",
      "4m 58s (- 2m 40s) (6500 65%) 2.3732\n",
      "500 lauseen Bag-Of-Words tarkkuus: 34.50777%\n",
      "5m 21s (- 2m 17s) (7000 70%) 2.2434\n",
      "500 lauseen Bag-Of-Words tarkkuus: 33.76238%\n",
      "5m 45s (- 1m 55s) (7500 75%) 2.2470\n",
      "500 lauseen Bag-Of-Words tarkkuus: 32.95229%\n",
      "6m 9s (- 1m 32s) (8000 80%) 2.2481\n",
      "500 lauseen Bag-Of-Words tarkkuus: 37.08333%\n",
      "6m 32s (- 1m 9s) (8500 85%) 2.1564\n",
      "500 lauseen Bag-Of-Words tarkkuus: 37.27273%\n",
      "6m 56s (- 0m 46s) (9000 90%) 2.1918\n",
      "500 lauseen Bag-Of-Words tarkkuus: 42.04661%\n",
      "7m 20s (- 0m 23s) (9500 95%) 1.9873\n",
      "500 lauseen Bag-Of-Words tarkkuus: 40.97686%\n",
      "7m 44s (- 0m 0s) (10000 100%) 2.0192\n",
      "500 lauseen Bag-Of-Words tarkkuus: 42.18513%\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 10000, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> opiskelen vielakin ranskaa .\n",
      "= i m still studying french .\n",
      "< i m studying french french . <EOS>\n",
      "\n",
      "> olemme naapureitanne .\n",
      "= we re your neighbors .\n",
      "< we re having . <EOS>\n",
      "\n",
      "> mina olen taalla pyytaakseni anteeksi .\n",
      "= i m here to apologize .\n",
      "< i m here . <EOS>\n",
      "\n",
      "> he ovat tosi rumia .\n",
      "= they re really ugly .\n",
      "< they re very . . <EOS>\n",
      "\n",
      "> han on kirjailija .\n",
      "= he is a writer .\n",
      "< she s a . <EOS>\n",
      "\n",
      "> kuolema pelottaa minua .\n",
      "= i m afraid of dying .\n",
      "< i m sorry to the . . <EOS>\n",
      "\n",
      "> tytto on itsepainen .\n",
      "= she s a stubborn girl .\n",
      "< she is a . . . <EOS>\n",
      "\n",
      "> odotan innolla huomista .\n",
      "= i m looking forward to tomorrow .\n",
      "< i m looking to my . . . <EOS>\n",
      "\n",
      "> menen kirkkoon .\n",
      "= i m going to church .\n",
      "< i m going to the . . <EOS>\n",
      "\n",
      "> en ole tyytyvainen taman paivan suoritukseeni .\n",
      "= i m not satisfied with my performance today .\n",
      "< i m not wearing to it . . <EOS>\n",
      "\n",
      "> olen hyvassa kunnossa .\n",
      "= i m fit .\n",
      "< i m very tired . <EOS>\n",
      "\n",
      "> heilla on molemmilla univormut .\n",
      "= they re both wearing uniforms .\n",
      "< we re all a bit . . <EOS>\n",
      "\n",
      "> mina en ole taalla .\n",
      "= i m not here .\n",
      "< i m not here . <EOS>\n",
      "\n",
      "> olen vahan aikaisessa .\n",
      "= i m a little early .\n",
      "< i m a little . <EOS>\n",
      "\n",
      "> kaivamme kaivon takapihalle .\n",
      "= we re digging a well in the backyard .\n",
      "< we re looking for your help . <EOS>\n",
      "\n",
      "> olen melkein varma siita .\n",
      "= i m almost sure of it .\n",
      "< i m sure sure that that . <EOS>\n",
      "\n",
      "> olet tarpeeksi vanha ymmartamaan .\n",
      "= you re old enough to understand .\n",
      "< you re a really without . <EOS>\n",
      "\n",
      "> meita se kiinnostaa .\n",
      "= we re interested .\n",
      "< we re having . . <EOS>\n",
      "\n",
      "> han on hulluna sinuun .\n",
      "= he is mad about you .\n",
      "< she is a little . . <EOS>\n",
      "\n",
      "> han ei ole laulaja vaan nayttelija .\n",
      "= he is not a singer but an actor .\n",
      "< she is not a at a . . <EOS>\n",
      "\n",
      "> olen tykastynyt lukemiseen .\n",
      "= i am fond of reading .\n",
      "< i m grateful for your . <EOS>\n",
      "\n",
      "> en ole aitisi .\n",
      "= i m not your mother .\n",
      "< i m not the . . <EOS>\n",
      "\n",
      "> han on koomikko .\n",
      "= he s a comedian .\n",
      "< she is a . . . <EOS>\n",
      "\n",
      "> han ei ole yhta pitka kuin hanen isansa .\n",
      "= he is not as tall as his father .\n",
      "< she is not a as as . <EOS>\n",
      "\n",
      "> mina tulen .\n",
      "= i m coming .\n",
      "< i m on . <EOS>\n",
      "\n",
      "> olen hyvin ujo .\n",
      "= i m very shy .\n",
      "< i m very tired . <EOS>\n",
      "\n",
      "> sina olet viela nuori .\n",
      "= you re still young .\n",
      "< you re still young . <EOS>\n",
      "\n",
      "> teen tyohakemusta .\n",
      "= i m applying for a job .\n",
      "< i m cooking . <EOS>\n",
      "\n",
      "> et ole tarpeeksi nopea .\n",
      "= you re not fast enough .\n",
      "< you re not a at . . <EOS>\n",
      "\n",
      "> olemme kanadalaisia .\n",
      "= we re canadians .\n",
      "< we re having . <EOS>\n",
      "\n",
      "> olet itsekas .\n",
      "= you re egotistical .\n",
      "< you re a . . <EOS>\n",
      "\n",
      "> olet tekemassa suurta virhetta .\n",
      "= you re making a terrible mistake .\n",
      "< you re a little like . <EOS>\n",
      "\n",
      "> han makaa sohvalla .\n",
      "= he is lying on the sofa .\n",
      "< she is always the . . <EOS>\n",
      "\n",
      "> olen sinun veljesi .\n",
      "= i m your brother .\n",
      "< i m sorry to you you . <EOS>\n",
      "\n",
      "> en ole ennustaja .\n",
      "= i am not a prophet .\n",
      "< i m not a . . <EOS>\n",
      "\n",
      "> olet ilkea .\n",
      "= you re wicked .\n",
      "< you re a . <EOS>\n",
      "\n",
      "> ma hapean mun menneisyytta .\n",
      "= i m ashamed of my past .\n",
      "< i m going to my . . <EOS>\n",
      "\n",
      "> sa oot kannissa .\n",
      "= you re drunk .\n",
      "< you are drunk . <EOS>\n",
      "\n",
      "> olet minun tyyppiani .\n",
      "= you re my type .\n",
      "< you are a . . <EOS>\n",
      "\n",
      "> han on ensirakkauteni .\n",
      "= he s my first love .\n",
      "< she s a . . . <EOS>\n",
      "\n",
      "> me olemme menossa leffaan .\n",
      "= we re going to the movies .\n",
      "< we re going to the . . <EOS>\n",
      "\n",
      "> olen hyvin kiinnostunut noista tarinoista .\n",
      "= i m very interested in those stories .\n",
      "< i m very interested in astronomy . <EOS>\n",
      "\n",
      "> olemme naapureitanne .\n",
      "= we re your neighbors .\n",
      "< we re having . <EOS>\n",
      "\n",
      "> minulla ei ole vaihtoehtoja .\n",
      "= i m out of options .\n",
      "< i m not sure . <EOS>\n",
      "\n",
      "> et ole melkein koskaan vaarassa .\n",
      "= you re almost never wrong .\n",
      "< you re not going to . . <EOS>\n",
      "\n",
      "> sina et auta .\n",
      "= you aren t helping .\n",
      "< you re not stupid . <EOS>\n",
      "\n",
      "> olen hulluna golfiin .\n",
      "= i am crazy about golf .\n",
      "< i m grateful . <EOS>\n",
      "\n",
      "> olet tosi ihana .\n",
      "= you re very sweet .\n",
      "< you are really best . <EOS>\n",
      "\n",
      "> sina olet omituinen tyyppi .\n",
      "= you re a weirdo .\n",
      "< you re a kind . <EOS>\n",
      "\n",
      "> ne ovat todella harmittomia .\n",
      "= they re really harmless .\n",
      "< they re very good . <EOS>\n",
      "\n",
      "> en ole tohtori .\n",
      "= i m not a doctor .\n",
      "< i m not sure . <EOS>\n",
      "\n",
      "> me olemme viela ystavia .\n",
      "= we re still friends .\n",
      "< we re still . . . <EOS>\n",
      "\n",
      "> kuuntelen radiota .\n",
      "= i m listening to the radio .\n",
      "< i m going to the . . <EOS>\n",
      "\n",
      "> me pysymme taalla .\n",
      "= we re staying here .\n",
      "< we re having here . <EOS>\n",
      "\n",
      "> han on taidemaalari .\n",
      "= he is a painter .\n",
      "< she is a . person . <EOS>\n",
      "\n",
      "> mina olen tottunut siihen .\n",
      "= i m used to it .\n",
      "< i m used to it . <EOS>\n",
      "\n",
      "> olen menossa kuntosalille .\n",
      "= i m off to the gym .\n",
      "< i m going to the . . <EOS>\n",
      "\n",
      "> mina pystyn puhumaan ranskaa .\n",
      "= i m able to speak french .\n",
      "< i m going to see a . . <EOS>\n",
      "\n",
      "> opiskelen englantia .\n",
      "= i m studying english .\n",
      "< i m going to the . . <EOS>\n",
      "\n",
      "> mina pelkaan sinun vaarinymmarteneen minut .\n",
      "= i m afraid you misunderstood me .\n",
      "< i m sorry to you you . <EOS>\n",
      "\n",
      "> heidat on erotettu toisistaan .\n",
      "= they re separated .\n",
      "< she is always . . . <EOS>\n",
      "\n",
      "> sinulla ei ole lainkaan karsivallisyytta minun kanssani .\n",
      "= you re so impatient with me .\n",
      "< you re not my . . . <EOS>\n",
      "\n",
      "> syy on minun .\n",
      "= i m to blame .\n",
      "< i m to my . . <EOS>\n",
      "\n",
      "> olen melko varma etta me tulemme haviamaan .\n",
      "= i m pretty sure that we ll lose .\n",
      "< i m pretty sure that we ll lose . <EOS>\n",
      "\n",
      "> opiskelen ranskaa nyt .\n",
      "= i m learning french now .\n",
      "< i m going to now . <EOS>\n",
      "\n",
      "> me olemme taalla turvassa eiko niin ?\n",
      "= we re safe in here aren t we ?\n",
      "< we re all here with me . <EOS>\n",
      "\n",
      "> minullakin on vahan nalka .\n",
      "= i m kind of hungry too .\n",
      "< i m a little busy . <EOS>\n",
      "\n",
      "> hanen kanssaan on hankala tulla toimeen .\n",
      "= he is hard to deal with .\n",
      "< we re all that . <EOS>\n",
      "\n",
      "> olen erittain kiinnostunut tahtitieteesta .\n",
      "= i m very interested in astronomy .\n",
      "< i m very interested in astronomy . <EOS>\n",
      "\n",
      "> mina olen aarimmaisen noyra ihminen .\n",
      "= i m an extremely humble person .\n",
      "< i m a little person . <EOS>\n",
      "\n",
      "> olen koukussa saippuaoopperoihin .\n",
      "= i m addicted to soap operas .\n",
      "< i m sorry to the . <EOS>\n",
      "\n",
      "> ei onnistu huijaamaan ketaan .\n",
      "= you re not fooling anyone .\n",
      "< you are not going to . <EOS>\n",
      "\n",
      "> anteeksi etta pilasin juhlasi .\n",
      "= i m sorry i ruined your party .\n",
      "< i m sorry to you you . <EOS>\n",
      "\n",
      "> he ovat vanhempia kuin tom .\n",
      "= they are older than tom .\n",
      "< they re a kind . . <EOS>\n",
      "\n",
      "> mina olen kotona .\n",
      "= i m at home .\n",
      "< i m on . <EOS>\n",
      "\n",
      "> sina et muuten mene sinne .\n",
      "= you re not going in there .\n",
      "< you re not stupid . <EOS>\n",
      "\n",
      "> olen piilossa .\n",
      "= i m hiding .\n",
      "< i m a . <EOS>\n",
      "\n",
      "> olen naimisissa ja minulla on kaksi lasta .\n",
      "= i am married and have two children .\n",
      "< i am married and have two two children . <EOS>\n",
      "\n",
      "> en yrita vierittaa vastuuta muille .\n",
      "= i m not placing blame .\n",
      "< i m not going to . . <EOS>\n",
      "\n",
      "> olen nikkaroimassa linnunponttoa .\n",
      "= i m building a birdhouse .\n",
      "< i m really a at . . <EOS>\n",
      "\n",
      "> mina en aina ole vapaalla sunnuntaisin .\n",
      "= i m not always free on sundays .\n",
      "< i m not always free on sundays . <EOS>\n",
      "\n",
      "> seisot jalallani .\n",
      "= you re standing on my foot .\n",
      "< you re a professor . <EOS>\n",
      "\n",
      "> olen varma etta tomi palaa pian .\n",
      "= i m sure tom will be back soon .\n",
      "< i m sure tom will that . <EOS>\n",
      "\n",
      "> mina olen kotona .\n",
      "= i m at home .\n",
      "< i m on . <EOS>\n",
      "\n",
      "> olen todella kiinnostunut ranskasta .\n",
      "= i am very interested in french .\n",
      "< i m very interested in astronomy . <EOS>\n",
      "\n",
      "> olen siviili .\n",
      "= i m a civilian .\n",
      "< i m really . . <EOS>\n",
      "\n",
      "> olen ilman puolustusta .\n",
      "= i m defenseless .\n",
      "< i m happy . <EOS>\n",
      "\n",
      "> olemme onnekkaita etta tomi on meilla taalla .\n",
      "= we re fortunate to have tom here .\n",
      "< we re all that is busy . <EOS>\n",
      "\n",
      "> mina olen rannalla .\n",
      "= i m at the beach .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> sinun seurassasi on hauskaa olla .\n",
      "= you re fun to hang out with .\n",
      "< you re fun to hang out with . <EOS>\n",
      "\n",
      "> opiskelen edelleen ranskaa .\n",
      "= i m still studying french .\n",
      "< i m looking for a . . <EOS>\n",
      "\n",
      "> tulin pelastamaan sinut .\n",
      "= i m here to save you .\n",
      "< i m sorry to you you . <EOS>\n",
      "\n",
      "> han on epavarma omasta tulevaisuudestaan .\n",
      "= he is uncertain about his future .\n",
      "< she is a kind person . <EOS>\n",
      "\n",
      "> han on lahjakas nuori ohjaaja .\n",
      "= he s a talented young director .\n",
      "< he is always young . <EOS>\n",
      "\n",
      "> sina olet meista kaikista pisin .\n",
      "= you are the tallest of us all .\n",
      "< you are a kind person i . <EOS>\n",
      "\n",
      "> mina vain varmistan .\n",
      "= i m just making sure .\n",
      "< i m sorry to . . <EOS>\n",
      "\n",
      "> sina et auta .\n",
      "= you re not helping .\n",
      "< you re not stupid . <EOS>\n",
      "\n",
      "> olet tosi hyvannakoinen .\n",
      "= you re a looker .\n",
      "< you re a professor . <EOS>\n",
      "\n",
      "> han on saalittava ja typera .\n",
      "= he s pathetic and stupid .\n",
      "< she is a little and . . <EOS>\n",
      "\n",
      "> han elaa onnetonta elamaa .\n",
      "= she is living an unhappy life .\n",
      "< she is a little of . . <EOS>\n",
      "\n",
      "> tuskin mina yksin tulen .\n",
      "= i m unlikely to come by myself .\n",
      "< i m sorry to you . <EOS>\n",
      "\n",
      "> mina kuolen nalkaan !\n",
      "= i m starved .\n",
      "< i m on . <EOS>\n",
      "\n",
      "> han on nuorempi kuin han .\n",
      "= she s younger than him .\n",
      "< she is a than than . <EOS>\n",
      "\n",
      "> sina mumiset taas .\n",
      "= you re mumbling again .\n",
      "< we re having to . . <EOS>\n",
      "\n",
      "> olen pankkitoimihenkilo .\n",
      "= i m a bank clerk .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> meilla on kiire .\n",
      "= we re in a hurry .\n",
      "< we re busy . <EOS>\n",
      "\n",
      "> olen pahoillani etta havisit .\n",
      "= i m sorry you lost .\n",
      "< i m sorry that you . <EOS>\n",
      "\n",
      "> oikea silmani on sokea .\n",
      "= i am blind in the right eye .\n",
      "< i m really to . . . <EOS>\n",
      "\n",
      "> he tyoskentelevat ylakerrassa .\n",
      "= they re working upstairs .\n",
      "< they re going to . . <EOS>\n",
      "\n",
      "> olet todella mukava mies tomi .\n",
      "= you re a really nice man tom .\n",
      "< you re a little man man tom . <EOS>\n",
      "\n",
      "> han on kiva .\n",
      "= he s a kind person .\n",
      "< she s a kind person . <EOS>\n",
      "\n",
      "> en ole aina sunnuntaisin vapaana .\n",
      "= i m not always free on sundays .\n",
      "< i m not always free on sundays . <EOS>\n",
      "\n",
      "> kayn miestenhuoneessa .\n",
      "= i m going to the men s room .\n",
      "< i m going to the . . <EOS>\n",
      "\n",
      "> olen todella koyha .\n",
      "= i m very poor .\n",
      "< i m very tired . <EOS>\n",
      "\n",
      "> olen taynna .\n",
      "= i am full .\n",
      "< i m on . <EOS>\n",
      "\n",
      "> tapaan tomin tana iltapaivana .\n",
      "= i m seeing tom this afternoon .\n",
      "< i m going to it . <EOS>\n",
      "\n",
      "> han on hyvin huolissaan terveydestasi .\n",
      "= she is very anxious about your health .\n",
      "< she is a at all . <EOS>\n",
      "\n",
      "> sina olet luotettava .\n",
      "= you re dependable .\n",
      "< you are a . . <EOS>\n",
      "\n",
      "> me asumme eri hotelissa .\n",
      "= we re staying in a different hotel .\n",
      "< we re trying to do . <EOS>\n",
      "\n",
      "> olen vihainen .\n",
      "= i m angry .\n",
      "< i m really . <EOS>\n",
      "\n",
      "> sina olet tosi hyva mies .\n",
      "= you re a real good man .\n",
      "< you are a good man man man . <EOS>\n",
      "\n",
      "> nyt olen rattivasynyt .\n",
      "= i m very tired now .\n",
      "< i m very tired . <EOS>\n",
      "\n",
      "> aina sina liioittelet .\n",
      "= you re always exaggerating .\n",
      "< you re fun . <EOS>\n",
      "\n",
      "> ne ovat suloisia .\n",
      "= they re adorable .\n",
      "< they re a . <EOS>\n",
      "\n",
      "> minulla on todella kiire .\n",
      "= i m very busy .\n",
      "< i m very busy . <EOS>\n",
      "\n",
      "> en ole tottunut puhumaan julkisesti .\n",
      "= i am not accustomed to speaking in public .\n",
      "< i m not used to do . <EOS>\n",
      "\n",
      "> olen yha naimisissa maryn kanssa .\n",
      "= i m still married to mary .\n",
      "< i m sorry to my s . . <EOS>\n",
      "\n",
      "> olen tottunut puhumaan siita .\n",
      "= i m used to talking about it .\n",
      "< i m used to it . <EOS>\n",
      "\n",
      "> han on harvoin jos koskaan myohassa tapaamisista .\n",
      "= he is rarely if ever late for appointments .\n",
      "< she is always to the the . . <EOS>\n",
      "\n",
      "> sina vitsailet !\n",
      "= you re joking !\n",
      "< you are drunk ! <EOS>\n",
      "\n",
      "> menen suoraan kotiin .\n",
      "= i m going straight home .\n",
      "< i m sorry to see . <EOS>\n",
      "\n",
      "> mina olen melko varma etta me haviamme .\n",
      "= i m pretty sure that we ll lose .\n",
      "< i m pretty sure that we ll lose . <EOS>\n",
      "\n",
      "> han pyytaa mahdottomia .\n",
      "= she s asking for the impossible .\n",
      "< he is eating to the . <EOS>\n",
      "\n",
      "> olet minun maassani .\n",
      "= you re on my land .\n",
      "< you are a professor . <EOS>\n",
      "\n",
      "> tulin tanne kokousta varten .\n",
      "= i m here for a meeting .\n",
      "< i m here to see you . <EOS>\n",
      "\n",
      "> sina olet paljon alykkaampi kuin mina .\n",
      "= you re much smarter than i am .\n",
      "< you are a really like you me . <EOS>\n",
      "\n",
      "> en ole pelkuri .\n",
      "= i m not a coward .\n",
      "< i m not a . . . <EOS>\n",
      "\n",
      "> olen tomin huonetoveri .\n",
      "= i m tom s roommate .\n",
      "< i m grateful to tom tom . <EOS>\n",
      "\n",
      "> en ole kilpailuhenkinen .\n",
      "= i m not competitive .\n",
      "< i m not sure . <EOS>\n",
      "\n",
      "> olen huolissani painostani .\n",
      "= i m worried about my weight .\n",
      "< i m grateful for my . <EOS>\n",
      "\n",
      "> han on se jolla on perhe .\n",
      "= she s the one with a family .\n",
      "< she is a the person . <EOS>\n",
      "\n",
      "> olen nyt valmis lahtemaan .\n",
      "= i m ready to leave now .\n",
      "< i m now to see now . <EOS>\n",
      "\n",
      "> han on kiva .\n",
      "= he is a nice person .\n",
      "< she is a kind person . <EOS>\n",
      "\n",
      "> han on erinominen aivokirurgi .\n",
      "= he s an excellent brain surgeon .\n",
      "< she is a at . . . <EOS>\n",
      "\n",
      "> taa ei oo vitsi .\n",
      "= i m not kidding about this .\n",
      "< i m not a at . . <EOS>\n",
      "\n",
      "> mulla on vahan kiire .\n",
      "= i m a little busy .\n",
      "< i m a little busy . <EOS>\n",
      "\n",
      "> ma olen tosissani .\n",
      "= i m being serious .\n",
      "< i m sorry . <EOS>\n",
      "\n",
      "> he ovat meidan asiakkaitamme .\n",
      "= they re our clients .\n",
      "< they re still . . <EOS>\n",
      "\n",
      "> painin ranskan kieliopin kanssa .\n",
      "= i m struggling with french grammar .\n",
      "< i m used to the . <EOS>\n",
      "\n",
      "> sina et ole edes viela kolmeakymmenta .\n",
      "= you re not even thirty yet .\n",
      "< you re not always yet . <EOS>\n",
      "\n",
      "> olen kissaihminen .\n",
      "= i m a cat person .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> me emme tee mitaan .\n",
      "= we re not doing anything .\n",
      "< we re not here . . <EOS>\n",
      "\n",
      "> olemme ansassa !\n",
      "= we re trapped !\n",
      "< we re joking ! <EOS>\n",
      "\n",
      "> olen samanikainen kuin sina .\n",
      "= i m the same age as you are .\n",
      "< i m sorry than you . <EOS>\n",
      "\n",
      "> olet haviaja .\n",
      "= you re a loser .\n",
      "< you are a . <EOS>\n",
      "\n",
      "> olen juuri nyt menossa sinne .\n",
      "= i m going there now .\n",
      "< i m going to the . . <EOS>\n",
      "\n",
      "> me olemme lounaalla .\n",
      "= we re having lunch .\n",
      "< we re having . . <EOS>\n",
      "\n",
      "> han on ranskasta .\n",
      "= he is from france .\n",
      "< she is a professor . <EOS>\n",
      "\n",
      "> sina et ole lihava .\n",
      "= you aren t fat .\n",
      "< you re not stupid . <EOS>\n",
      "\n",
      "> olen esiliinasi .\n",
      "= i m your chaperone .\n",
      "< i m your . . <EOS>\n",
      "\n",
      "> olen eksynyt .\n",
      "= i am lost .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> minulla on koti ikava .\n",
      "= i m homesick .\n",
      "< i m pretty sure . <EOS>\n",
      "\n",
      "> vastauksesi oli hammentava .\n",
      "= i m puzzled by your reaction .\n",
      "< i m used to the . . <EOS>\n",
      "\n",
      "> han on yksi leveilija .\n",
      "= he is such a show off .\n",
      "< she is a kind . <EOS>\n",
      "\n",
      "> otan vahan rennosti .\n",
      "= i m taking it easy .\n",
      "< i m a little . . <EOS>\n",
      "\n",
      "> lennan bostoniin huomenna .\n",
      "= i m flying to boston tomorrow .\n",
      "< i m going to the . . <EOS>\n",
      "\n",
      "> olemme yhdessa kiinni tassa asiassa eiko niin ?\n",
      "= we re in this thing together right ?\n",
      "< we re all to the . . <EOS>\n",
      "\n",
      "> en ole oikeastaan asiantuntija .\n",
      "= i m not really an expert .\n",
      "< i m not in the . . . <EOS>\n",
      "\n",
      "> tulen myohastymaan toista .\n",
      "= i m going to be late for work .\n",
      "< i m going to see a . . <EOS>\n",
      "\n",
      "> tunnen oloni hieman apeaksi tanaan .\n",
      "= i m feeling a little blue today .\n",
      "< i m really to hang out with . <EOS>\n",
      "\n",
      "> oletpa hiljainen tanaan .\n",
      "= you re very quiet today .\n",
      "< we re having . . <EOS>\n",
      "\n",
      "> olen vahan ujo .\n",
      "= i m a bit shy .\n",
      "< i m a little . <EOS>\n",
      "\n",
      "> pelkaan ettei tom pysty siihen .\n",
      "= i m afraid tom can t do it .\n",
      "< i m sorry to tom tom is . <EOS>\n",
      "\n",
      "> han on paljon minua nokkelampi .\n",
      "= he is much smarter than i am .\n",
      "< he is a little and . <EOS>\n",
      "\n",
      "> oppia ika kaikki .\n",
      "= you re never too old to learn .\n",
      "< i m going to hang out with . <EOS>\n",
      "\n",
      "> olen addiktoitunut .\n",
      "= i m addicted .\n",
      "< i m really . <EOS>\n",
      "\n",
      "> sina hopiset .\n",
      "= you re babbling .\n",
      "< you re not . . <EOS>\n",
      "\n",
      "> olen kokki .\n",
      "= i am a cook .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> olet tunteeton .\n",
      "= you re callous .\n",
      "< you re a . <EOS>\n",
      "\n",
      "> olen taman koulun oppilas .\n",
      "= i am a student of this school .\n",
      "< i m grateful for what you . <EOS>\n",
      "\n",
      "> ma oon huolissani susta .\n",
      "= i m worried about you .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> emme me niin tyhmia ole .\n",
      "= we aren t that stupid .\n",
      "< we re not sure that . <EOS>\n",
      "\n",
      "> mina en juo tana iltana .\n",
      "= i m not drinking tonight .\n",
      "< i m not going to . . <EOS>\n",
      "\n",
      "> etsin toita bostonista .\n",
      "= i m looking for a job in boston .\n",
      "< i m looking for a for you . <EOS>\n",
      "\n",
      "> ihme hiihtaja .\n",
      "= he s a weird guy .\n",
      "< you re going to . . <EOS>\n",
      "\n",
      "> me odotamme kaupan aukeamista .\n",
      "= we re waiting for the shop to open .\n",
      "< we re all on the . . <EOS>\n",
      "\n",
      "> han pelkaa kaarmeita .\n",
      "= he is afraid of snakes .\n",
      "< he is not a of . . <EOS>\n",
      "\n",
      "> olen iloinen etta olet samaa mielta .\n",
      "= i m glad you agree .\n",
      "< i m sorry you you re <EOS>\n",
      "\n",
      "> olet todella komea mies tom .\n",
      "= you re a very handsome man tom .\n",
      "< you re a little man tom . <EOS>\n",
      "\n",
      "> han on hyvalla tuulella tanaan .\n",
      "= he is in high spirits today .\n",
      "< she is a little busy . <EOS>\n",
      "\n",
      "> minun oikea silmani on sokea .\n",
      "= i am blind in the right eye .\n",
      "< i m going to . . <EOS>\n",
      "\n",
      "> han on pelkkana korvana .\n",
      "= he is giving his whole attention to that .\n",
      "< she is a little . . . <EOS>\n",
      "\n",
      "> han on koyha mutta nayttaa onnelliselta .\n",
      "= she is poor but she looks happy .\n",
      "< she is a kind person . <EOS>\n",
      "\n",
      "> olen perfektionisti .\n",
      "= i m a perfectionist .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> me olemme todella ylpeita sinusta .\n",
      "= we re very proud of you .\n",
      "< we re very sure that you . <EOS>\n",
      "\n",
      "> ma en oo kotona .\n",
      "= i m not home .\n",
      "< i m not a at . <EOS>\n",
      "\n",
      "> en ole lainkaan kiinnostunut politiikasta .\n",
      "= i am not interested in politics at all .\n",
      "< i m not interested in astronomy . <EOS>\n",
      "\n",
      "> mina en mene mihinkaan sinun kanssasi .\n",
      "= i m not going anywhere with you .\n",
      "< i m not going to you you . <EOS>\n",
      "\n",
      "> olen todella pahoillani siita mita tapahtui .\n",
      "= i m very sorry about what happened .\n",
      "< i m very sorry to you you . <EOS>\n",
      "\n",
      "> he ovat omavaraisia .\n",
      "= they re self sufficient .\n",
      "< they re friends . <EOS>\n",
      "\n",
      "> olen todella ylpea itsestani .\n",
      "= i m very proud of myself .\n",
      "< i m very tired . . <EOS>\n",
      "\n",
      "> olet todella hyva laulaja .\n",
      "= you re really a good singer .\n",
      "< you re a good . <EOS>\n",
      "\n",
      "> mina olen luova .\n",
      "= i m creative .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> olemme jumissa liikenteessa .\n",
      "= we re stuck in traffic .\n",
      "< we re having friends . <EOS>\n",
      "\n",
      "> annan sen sinulle ilmaiseksi .\n",
      "= i m giving it to you for free .\n",
      "< i m sorry to you you you . <EOS>\n",
      "\n",
      "> olen vapaana .\n",
      "= i m free .\n",
      "< i m on . <EOS>\n",
      "\n",
      "> en ole turisti .\n",
      "= i m not a tourist .\n",
      "< i m not a at . <EOS>\n",
      "\n",
      "> he ovat lahdossa .\n",
      "= they re about to leave .\n",
      "< they re going . <EOS>\n",
      "\n",
      "> olen valmis nukkumaan .\n",
      "= i m ready for bed .\n",
      "< i m a little . . <EOS>\n",
      "\n",
      "> han on sekaisin .\n",
      "= she s crazy .\n",
      "< she is a . . <EOS>\n",
      "\n",
      "> en allekirjoita sita .\n",
      "= i m not signing it .\n",
      "< i m not to it . <EOS>\n",
      "\n",
      "> han asuu hotellissa .\n",
      "= he s staying at a hotel .\n",
      "< he s not a at . <EOS>\n",
      "\n",
      "> havettaa kauheasti .\n",
      "= i am deeply ashamed .\n",
      "< i am looking . <EOS>\n",
      "\n",
      "> he ovat apeita .\n",
      "= they re blue .\n",
      "< they re friends . <EOS>\n",
      "\n",
      "> han on vahan pidempi kuin sina .\n",
      "= he s a little taller than you are .\n",
      "< she s a little than you . <EOS>\n",
      "\n",
      "> han on isansa kaltainen .\n",
      "= he is similar to his father .\n",
      "< she is the his . . <EOS>\n",
      "\n",
      "> han menetti mahdollisuutensa .\n",
      "= he s missed the boat .\n",
      "< he is the the . . . <EOS>\n",
      "\n",
      "> olemme justiinsa lahdossa .\n",
      "= we re about to hit the road .\n",
      "< we re all to the . . <EOS>\n",
      "\n",
      "> minua alkaa vasyttaa .\n",
      "= i m beginning to get tired .\n",
      "< i m sorry to the . . <EOS>\n",
      "\n",
      "> kokkaan .\n",
      "= i m cooking .\n",
      "< i m going to <EOS>\n",
      "\n",
      "> kaikki janoamme maailmanrauhaa .\n",
      "= we are all eager for world peace .\n",
      "< we re all on you . <EOS>\n",
      "\n",
      "> han on kiltti .\n",
      "= he is kind .\n",
      "< she s a kind person . <EOS>\n",
      "\n",
      "> ma oon bilehile .\n",
      "= i m a party animal .\n",
      "< i m very . . <EOS>\n",
      "\n",
      "> olet liian nuori ymmartamaan .\n",
      "= you re too young to understand .\n",
      "< you re too too . . <EOS>\n",
      "\n",
      "> olen naimisissa ja minulla on kaksi lasta .\n",
      "= i am married and have two children .\n",
      "< i am married and have two two children . <EOS>\n",
      "\n",
      "> anteeksi etta olen myohassa .\n",
      "= i m sorry about being late .\n",
      "< i m sorry for you . <EOS>\n",
      "\n",
      "> hanella on hella sydan .\n",
      "= he is kind at heart .\n",
      "< she is the his . <EOS>\n",
      "\n",
      "> olen oikeudenmukainen .\n",
      "= i m fair .\n",
      "< i m really . <EOS>\n",
      "\n",
      "> han on kiltti ihminen .\n",
      "= she s a kind person .\n",
      "< she is a kind person . <EOS>\n",
      "\n",
      "> hammennat tomia .\n",
      "= you re confusing tom .\n",
      "< i m sorry to tom . <EOS>\n",
      "\n",
      "> en ole luova .\n",
      "= i m not creative .\n",
      "< i m not . . <EOS>\n",
      "\n",
      "> han teeskentelee .\n",
      "= he s faking .\n",
      "< she is the . . <EOS>\n",
      "\n",
      "> olet kuumis .\n",
      "= you re a hottie .\n",
      "< you re a professor . <EOS>\n",
      "\n",
      "> han on mies joka piirsi kuvan .\n",
      "= he is the man who drew the picture .\n",
      "< she is a little man . <EOS>\n",
      "\n",
      "> han on aina kanssani .\n",
      "= he is always with me .\n",
      "< she is always busy . <EOS>\n",
      "\n",
      "> en ole hyvassa kunnossa .\n",
      "= i m not in good shape .\n",
      "< i m not very at . <EOS>\n",
      "\n",
      "> mina menen .\n",
      "= i m going .\n",
      "< i m going to . . <EOS>\n",
      "\n",
      "> ma tyostan yhta projektia .\n",
      "= i m working on a project .\n",
      "< i m sorry to the . . <EOS>\n",
      "\n",
      "> olen sankari .\n",
      "= i m a hero .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> me kaikki tulemme kuolemaan .\n",
      "= we are all going to die .\n",
      "< we re all on the . . <EOS>\n",
      "\n",
      "> olen taalla tomin takia .\n",
      "= i m here because of tom .\n",
      "< i m here to tom tom . <EOS>\n",
      "\n",
      "> etsin silmalasejani .\n",
      "= i am looking for my glasses .\n",
      "< i m looking for you . <EOS>\n",
      "\n",
      "> etsin veljeani .\n",
      "= i am looking for my brother .\n",
      "< i m looking for your you . <EOS>\n",
      "\n",
      "> anteeksi jos heratin sinut .\n",
      "= i m sorry if i woke you .\n",
      "< i m sorry to you you . <EOS>\n",
      "\n",
      "> he ovat hyvin alykkaita .\n",
      "= they re very smart .\n",
      "< they re very friends . <EOS>\n",
      "\n",
      "> olet kuuluisa .\n",
      "= you re famous .\n",
      "< you re a . . <EOS>\n",
      "\n",
      "> han on korviaan myoten rakastunut .\n",
      "= he s love struck .\n",
      "< she is a to . . . <EOS>\n",
      "\n",
      "> he ovat nalkaisia .\n",
      "= they are hungry .\n",
      "< they re a . <EOS>\n",
      "\n",
      "> olen aika varma etta haviamme .\n",
      "= i m pretty sure that we ll lose .\n",
      "< i m pretty sure that we ll lose . <EOS>\n",
      "\n",
      "> anteeksi sanoitko jotakin ?\n",
      "= i m sorry did you say something ?\n",
      "< i m sorry to you you . <EOS>\n",
      "\n",
      "> olen iloinen etta tom on kunnossa .\n",
      "= i m glad tom is ok .\n",
      "< i m glad tom is tom . <EOS>\n",
      "\n",
      "> olen vanhanaikainen .\n",
      "= i m old fashioned .\n",
      "< i m sorry . <EOS>\n",
      "\n",
      "> en ole vakuuttunut .\n",
      "= i m unconvinced .\n",
      "< i m not sure . <EOS>\n",
      "\n",
      "> olet varmasti vasynyt .\n",
      "= i m sure you re tired .\n",
      "< i m really tired . <EOS>\n",
      "\n",
      "> painoni huolettaa minua .\n",
      "= i m worried about my weight .\n",
      "< i m really like . <EOS>\n",
      "\n",
      "> he taistelevat vapauden puolesta .\n",
      "= they are struggling for freedom .\n",
      "< they re still young . <EOS>\n",
      "\n",
      "> olen alykas .\n",
      "= i m smart .\n",
      "< i m on . <EOS>\n",
      "\n",
      "> olet tyrmaava .\n",
      "= you re a knockout .\n",
      "< you are a professor . <EOS>\n",
      "\n",
      "> han on itsepainen .\n",
      "= she is stubborn .\n",
      "< she is a . . . <EOS>\n",
      "\n",
      "> olen piilossa .\n",
      "= i m hiding .\n",
      "< i m a . <EOS>\n",
      "\n",
      "> olemme taas aikataulussa .\n",
      "= we re back on schedule .\n",
      "< we re having the . . <EOS>\n",
      "\n",
      "> han pesee autoa .\n",
      "= she is washing the car .\n",
      "< she is the the . . . <EOS>\n",
      "\n",
      "> mina olen aivan yhta hammentynyt kuin sinakin .\n",
      "= i m just as confused as you are .\n",
      "< i m very tired to you . <EOS>\n",
      "\n",
      "> hanen kerrotaan kuolleen taalla .\n",
      "= he is said to have died here .\n",
      "< we re trying here here . <EOS>\n",
      "\n",
      "> he ovat perhetta .\n",
      "= they re family .\n",
      "< they re a . <EOS>\n",
      "\n",
      "> han on lahjakas nuori ohjaaja .\n",
      "= he s a talented young director .\n",
      "< she is a young . <EOS>\n",
      "\n",
      "> olen poliisi .\n",
      "= i m a cop .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> he tarkkailevat sinua .\n",
      "= they re watching you .\n",
      "< they re really . . <EOS>\n",
      "\n",
      "> syon .\n",
      "= i m eating .\n",
      "< i m a little . <EOS>\n",
      "\n",
      "> en ole kovin itsevarma .\n",
      "= i m not very confident .\n",
      "< i m not good . <EOS>\n",
      "\n",
      "> ne ovat todella vaarallisia .\n",
      "= they re very dangerous .\n",
      "< they re very . . <EOS>\n",
      "\n",
      "> han on ystavallinen ihminen .\n",
      "= he is kind .\n",
      "< she is a kind person . <EOS>\n",
      "\n",
      "> en ole huolissani heista .\n",
      "= i m not worried about them .\n",
      "< i m not married . <EOS>\n",
      "\n",
      "> nautin tasta kirjasta suuresti .\n",
      "= i m really enjoying this book .\n",
      "< i m sorry to it . <EOS>\n",
      "\n",
      "> olen yksinainen .\n",
      "= i m lonely .\n",
      "< i m sorry . <EOS>\n",
      "\n",
      "> en ole vakivaltainen ihminen .\n",
      "= i m not a violent person .\n",
      "< i m not a person . <EOS>\n",
      "\n",
      "> han ei ole kotona vaan koulussa .\n",
      "= she is not home but at school .\n",
      "< she is not a at all . <EOS>\n",
      "\n",
      "> olette tyhmia .\n",
      "= you re stupid .\n",
      "< you are stupid . <EOS>\n",
      "\n",
      "> olen tosi lihava .\n",
      "= i m extremely fat .\n",
      "< i m really fat . <EOS>\n",
      "\n",
      "> en ole laakari .\n",
      "= i m not a doctor .\n",
      "< i m not a . . <EOS>\n",
      "\n",
      "> hanen kanssaan on hankala tulla toimeen .\n",
      "= he is hard to deal with .\n",
      "< we re all that . <EOS>\n",
      "\n",
      "> pariskunta nayttaa onnelliselta .\n",
      "= they re a happy looking couple .\n",
      "< you re fun to hang . <EOS>\n",
      "\n",
      "> he ovat viela taalla .\n",
      "= they re still here .\n",
      "< they re still here . <EOS>\n",
      "\n",
      "> yritan vain olla johdonmukainen .\n",
      "= i m just trying to be consistent .\n",
      "< i m sorry to hang out with . <EOS>\n",
      "\n",
      "> han on kuuluisa laulaja .\n",
      "= she is a well known singer .\n",
      "< she is a kind . . <EOS>\n",
      "\n",
      "> olen koiraihmisia .\n",
      "= i am a dog person .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> en ole yhtaan huolissani .\n",
      "= i m not the least bit worried .\n",
      "< i m not sure . . <EOS>\n",
      "\n",
      "> olen aviossa ja minulla on kaksi poikaa .\n",
      "= i am married and i have two sons .\n",
      "< i am married and and have two two sons .\n",
      "\n",
      "> han on ihailtava nainen .\n",
      "= she s an admirable woman .\n",
      "< she is a a person . <EOS>\n",
      "\n",
      "> te olette vaarassa .\n",
      "= you re wrong .\n",
      "< you are stupid . <EOS>\n",
      "\n",
      "> olemme uppoamassa .\n",
      "= we re sinking .\n",
      "< we re a . . <EOS>\n",
      "\n",
      "> en ole tottunut tahan .\n",
      "= i m not accustomed to doing this .\n",
      "< i m not at this . . <EOS>\n",
      "\n",
      "> olen pahoillani en voi jaada pitkaksi aikaa .\n",
      "= i m sorry i can t stay long .\n",
      "< i m sorry to that you . <EOS>\n",
      "\n",
      "> olen melko varma etta tulemme haviamaan .\n",
      "= i m pretty sure that we ll lose .\n",
      "< i m pretty sure that we ll lose . <EOS>\n",
      "\n",
      "> me menemme .\n",
      "= we re going .\n",
      "< we re having . <EOS>\n",
      "\n",
      "> en ole perfektionisti .\n",
      "= i m not a perfectionist .\n",
      "< i m not a . . <EOS>\n",
      "\n",
      "> olen luotettava .\n",
      "= i m trustworthy .\n",
      "< i m on . <EOS>\n",
      "\n",
      "> minulla menee ihan hyvin .\n",
      "= i m quite well .\n",
      "< i m on the . . <EOS>\n",
      "\n",
      "> olen rakastunut toiseen .\n",
      "= i m in love with someone else .\n",
      "< i m a little . . <EOS>\n",
      "\n",
      "> odotan kovasti ensi viikonloppua .\n",
      "= i m looking forward to this weekend .\n",
      "< i m looking to keep you . <EOS>\n",
      "\n",
      "> han on rahaton .\n",
      "= he s broke .\n",
      "< she is a . . <EOS>\n",
      "\n",
      "> olet luennoitsija .\n",
      "= you are a professor .\n",
      "< you are a . . <EOS>\n",
      "\n",
      "> viihdyn seurassasi .\n",
      "= you re fun to hang out with .\n",
      "< you re fun to hang out with . <EOS>\n",
      "\n",
      "> olen vapaa .\n",
      "= i m free .\n",
      "< i m on . <EOS>\n",
      "\n",
      "> tulen olemaan huoneessani .\n",
      "= i m going to be in my room .\n",
      "< i m sorry to see you . <EOS>\n",
      "\n",
      "> olen masentunut .\n",
      "= i m depressed .\n",
      "< i m sorry . <EOS>\n",
      "\n",
      "> he tarkkailevat minua .\n",
      "= they re watching me .\n",
      "< they re really . . <EOS>\n",
      "\n",
      "> mina olen pidempi .\n",
      "= i am taller .\n",
      "< i m very . <EOS>\n",
      "\n",
      "> han on nyt nainen .\n",
      "= she s a woman now .\n",
      "< she is a kind person . <EOS>\n",
      "\n",
      "> mina pyrin pitamaan tuomon elossa .\n",
      "= i m trying to keep tom alive .\n",
      "< i m trying to keep tom alive . <EOS>\n",
      "\n",
      "> lahden australiasta huomenna .\n",
      "= i m leaving for australia tomorrow .\n",
      "< i m going to go . <EOS>\n",
      "\n",
      "> olette aivan oikeassa .\n",
      "= you are absolutely right .\n",
      "< you are really best . <EOS>\n",
      "\n",
      "> selityksesi ovat lopussa .\n",
      "= you re out of excuses .\n",
      "< i m a . . . <EOS>\n",
      "\n",
      "> kadun sita mita tein .\n",
      "= i m sorry for what i have done .\n",
      "< i m sorry to see tom . <EOS>\n",
      "\n",
      "> he ovat yha nuoria .\n",
      "= they re still young .\n",
      "< they re still young . <EOS>\n",
      "\n",
      "> olen paljon sinua isompi .\n",
      "= i m a lot bigger than you are .\n",
      "< i m grateful for you you . <EOS>\n",
      "\n",
      "> han on viela nuori .\n",
      "= he is still young .\n",
      "< she is not young . <EOS>\n",
      "\n",
      "> olet niin kiltti .\n",
      "= you re so kind .\n",
      "< you re a professor . <EOS>\n",
      "\n",
      "> etenemme hienosti .\n",
      "= we re making good progress .\n",
      "< we re looking . <EOS>\n",
      "\n",
      "> olen yhdysvaltain kansalainen .\n",
      "= i m a us citizen .\n",
      "< i m a little . . <EOS>\n",
      "\n",
      "> han on todella alykas eiko totta ?\n",
      "= she s really smart isn t she ?\n",
      "< she is always at me ? <EOS>\n",
      "\n",
      "> olen vahan vasynyt .\n",
      "= i m a bit tired .\n",
      "< i m a little tired . <EOS>\n",
      "\n",
      "> he ovat puhumassa .\n",
      "= they re talking .\n",
      "< they re friends . <EOS>\n",
      "\n",
      "> odotan joulua innolla .\n",
      "= i am looking forward to christmas .\n",
      "< i am looking for a for you . <EOS>\n",
      "\n",
      "> han on vanha .\n",
      "= he is old .\n",
      "< she is a . . <EOS>\n",
      "\n",
      "> olet todella ylimielinen .\n",
      "= you re very arrogant .\n",
      "< you re a good . <EOS>\n",
      "\n",
      "> et ole lapsi enaa .\n",
      "= you re not a kid anymore .\n",
      "< you re not a . . . <EOS>\n",
      "\n",
      "> en ole epajarjestelmallinen .\n",
      "= i m not disorganized .\n",
      "< i m not . . <EOS>\n",
      "\n",
      "> olet ainoa toivomme .\n",
      "= you re our only hope .\n",
      "< you re a professor . <EOS>\n",
      "\n",
      "> olet kolmekymmenta vai ?\n",
      "= you re thirty right ?\n",
      "< you are a aren you ? <EOS>\n",
      "\n",
      "> han leikkii taalla .\n",
      "= he is playing here .\n",
      "< he is here here . <EOS>\n",
      "\n",
      "> puhun totta sinulle .\n",
      "= i m telling you the truth .\n",
      "< i m trying to you you . <EOS>\n",
      "\n",
      "> minua alkaa huimata .\n",
      "= i m getting dizzy .\n",
      "< i m sorry to the . <EOS>\n",
      "\n",
      "> mina kuuntelen radiota .\n",
      "= i m listening to the radio .\n",
      "< i m going to the . . <EOS>\n",
      "\n",
      "> minulla ei ole latin latia .\n",
      "= i m broke .\n",
      "< i m not a at a . <EOS>\n",
      "\n",
      "> he ovat saalittavia .\n",
      "= they re pathetic .\n",
      "< they re friends . <EOS>\n",
      "\n",
      "> olemme menossa leffaan tanaan illalla .\n",
      "= we re going to the movies tonight .\n",
      "< we re all to the the . . <EOS>\n",
      "\n",
      "> han on ainoa lapsi .\n",
      "= she is only a child .\n",
      "< she is a kind . . <EOS>\n",
      "\n",
      "> tupakoiminen on taalla kielletty .\n",
      "= you re prohibited from smoking here .\n",
      "< we re all to . . . <EOS>\n",
      "\n",
      "> tuhlaat ammuksia .\n",
      "= you re wasting ammo .\n",
      "< you re fun to hang . <EOS>\n",
      "\n",
      "> han on kotoisin ranskasta .\n",
      "= she is from france .\n",
      "< he s a little . . <EOS>\n",
      "\n",
      "> sina olet niin tyhma .\n",
      "= you are so stupid .\n",
      "< you are stupid . <EOS>\n",
      "\n",
      "> olen matkalla kotiin .\n",
      "= i m on my way home .\n",
      "< i m sorry for you . <EOS>\n",
      "\n",
      "> olet hyva ihminen .\n",
      "= you re a good man .\n",
      "< you re a good . <EOS>\n",
      "\n",
      "> me parjaamme paremmin ilman teita .\n",
      "= we re better off without you .\n",
      "< we re all like me . <EOS>\n",
      "\n",
      "> olen vain opettaja .\n",
      "= i m just a teacher .\n",
      "< i m sorry to you you . <EOS>\n",
      "\n",
      "> olen asiakas .\n",
      "= i m a client .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> aion ottaa autoni .\n",
      "= i m going to take my car .\n",
      "< i m going to the . . <EOS>\n",
      "\n",
      "> han on edelleen toissa .\n",
      "= he s still at work .\n",
      "< he is still at . . <EOS>\n",
      "\n",
      "> olet ottamassa aikamoisen riskin .\n",
      "= you re taking quite a risk .\n",
      "< you re all a bit . <EOS>\n",
      "\n",
      "> mina aion opiskella ranskaa .\n",
      "= i m going to study french .\n",
      "< i m going to see a . . <EOS>\n",
      "\n",
      "> mina olen kohtuullisen varma etta me tulemme haviamaan .\n",
      "= i m pretty sure that we ll lose .\n",
      "< i m pretty sure that we ll lose . <EOS>\n",
      "\n",
      "> han on hyvalla tuulella tanaan .\n",
      "= he is in high spirits today .\n",
      "< she is a little busy . <EOS>\n",
      "\n",
      "> minulla on aikaa .\n",
      "= i m free .\n",
      "< i m on . <EOS>\n",
      "\n",
      "> ette auta .\n",
      "= you aren t helping .\n",
      "< you re not . . <EOS>\n",
      "\n",
      "> alan valmistautua pahimpaan .\n",
      "= i m getting ready for the worst .\n",
      "< i m going to see a . <EOS>\n",
      "\n",
      "> sina et ole edes viela kolmeakymmenta .\n",
      "= you re not even thirty yet .\n",
      "< you re not always yet . <EOS>\n",
      "\n",
      "> suuntaamme takaisin kaupunkiin .\n",
      "= we re heading back to town .\n",
      "< we re having to . . <EOS>\n",
      "\n",
      "> han on mustasukkainen mies .\n",
      "= he is a jealous man .\n",
      "< she s a man man . <EOS>\n",
      "\n",
      "> olen aika varma etta tulemme haviamaan .\n",
      "= i m pretty sure that we ll lose .\n",
      "< i m pretty sure that we ll lose . <EOS>\n",
      "\n",
      "> olet niin kiva .\n",
      "= you re so nice .\n",
      "< you re a professor . <EOS>\n",
      "\n",
      "> olet vanha .\n",
      "= you re old .\n",
      "< you are a . <EOS>\n",
      "\n",
      "> en tule pettamaan sinua .\n",
      "= i am not going to betray you .\n",
      "< i m not to you you . <EOS>\n",
      "\n",
      "> olet outo tyyppi .\n",
      "= you re a freak .\n",
      "< you re a kind . <EOS>\n",
      "\n",
      "> etsimme passejamme .\n",
      "= we re looking for our passports .\n",
      "< we re looking for your . <EOS>\n",
      "\n",
      "> tulin pelastamaan sinut .\n",
      "= i m here to save you .\n",
      "< i m sorry to you you . <EOS>\n",
      "\n",
      "> naytat hyvalta .\n",
      "= you re looking good !\n",
      "< i m looking for you . <EOS>\n",
      "\n",
      "> en tule puhumaan siita .\n",
      "= i m not going to talk about that .\n",
      "< i m not sure to it . <EOS>\n",
      "\n",
      "> te olette edelleen kokemattomia .\n",
      "= you re still green .\n",
      "< you are still green . <EOS>\n",
      "\n",
      "> olen varma etta sina onnistut .\n",
      "= i m sure that you ll succeed .\n",
      "< i m sure that you ll . <EOS>\n",
      "\n",
      "> minakin olen kiinnostunut kreikkalaisesta mytologiasta .\n",
      "= i m also interested in greek mythology .\n",
      "< i m very grateful to you . <EOS>\n",
      "\n",
      "> mekaan emme ole neroja .\n",
      "= we re not geniuses either .\n",
      "< we re not sure that . <EOS>\n",
      "\n",
      "> me syomme lounasta .\n",
      "= we re having lunch .\n",
      "< we re having . . <EOS>\n",
      "\n",
      "> olen oikeudenmukainen .\n",
      "= i m fair .\n",
      "< i m really . <EOS>\n",
      "\n",
      "> minun oikea silmani on sokea .\n",
      "= i am blind in the right eye .\n",
      "< i m going to . . <EOS>\n",
      "\n",
      "> han on erittain ymmartavainen .\n",
      "= he s very understanding .\n",
      "< she is always at . . <EOS>\n",
      "\n",
      "> han on erittain ymmartavainen .\n",
      "= he s very understanding .\n",
      "< she is always busy . <EOS>\n",
      "\n",
      "> he tappavat minut .\n",
      "= they re going to kill me .\n",
      "< they re going to hang out . <EOS>\n",
      "\n",
      "> han on hanen ystavansa .\n",
      "= he s her friend .\n",
      "< she is a kind . <EOS>\n",
      "\n",
      "> olet tarkka .\n",
      "= you re particular .\n",
      "< you re a . <EOS>\n",
      "\n",
      "> te olette kannissa !\n",
      "= you are drunk !\n",
      "< you are drunk ! <EOS>\n",
      "\n",
      "> olen kirjanpitaja .\n",
      "= i m a bookkeeper .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> olen huvittunut .\n",
      "= i m amused .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> tuskin tulen yksin .\n",
      "= i m unlikely to come by myself .\n",
      "< i m going to you you . <EOS>\n",
      "\n",
      "> mina ajattelen sinua .\n",
      "= i m thinking of you .\n",
      "< i m sorry to you you . <EOS>\n",
      "\n",
      "> en ole kovin hyva ranskassa .\n",
      "= i m not very good at french .\n",
      "< i m not good at at . <EOS>\n",
      "\n",
      "> en ole karsivallinen .\n",
      "= i m not patient .\n",
      "< i m not a . . <EOS>\n",
      "\n",
      "> he molemmat ovat hyvin patevia tuomareita .\n",
      "= they are both very competent judges .\n",
      "< they re a very nice . <EOS>\n",
      "\n",
      "> olette tyhmia .\n",
      "= you are stupid .\n",
      "< you are stupid . <EOS>\n",
      "\n",
      "> han on kiltti .\n",
      "= he s a kind person .\n",
      "< she s a kind person . <EOS>\n",
      "\n",
      "> en ole kiireinen .\n",
      "= i m not in a hurry .\n",
      "< i m not sure . <EOS>\n",
      "\n",
      "> tuo nyt on hiusten halkomista .\n",
      "= you re splitting hairs .\n",
      "< you re a little right now . <EOS>\n",
      "\n",
      "> sinusta ei ole mitaan hyotya .\n",
      "= you re useless .\n",
      "< you re not sure . <EOS>\n",
      "\n",
      "> mina olen varma etta tomi haluaa auttaa sinua .\n",
      "= i m sure tom will help you .\n",
      "< i m sure that you you you . <EOS>\n",
      "\n",
      "> olen erittain kiinnostunut astronomiasta .\n",
      "= i m very interested in astronomy .\n",
      "< i m very interested in astronomy . <EOS>\n",
      "\n",
      "> anteeksi etta olen myohassa .\n",
      "= i m sorry for being late .\n",
      "< i m sorry for you . <EOS>\n",
      "\n",
      "> mina olen aivan paksu .\n",
      "= i m very fat .\n",
      "< i m very tired . <EOS>\n",
      "\n",
      "> olen suuttunut tomille .\n",
      "= i m angry with tom .\n",
      "< i m grateful to tom tom . <EOS>\n",
      "\n",
      "> he ovat todennakoisesti jo kuolleita .\n",
      "= they re probably already dead .\n",
      "< they re a kind person . <EOS>\n",
      "\n",
      "> olet vain vainoharhainen .\n",
      "= you re just being paranoid .\n",
      "< you re a professor . <EOS>\n",
      "\n",
      "> olen aviossa ja minulla on kaksi poikaa .\n",
      "= i am married and i have two sons .\n",
      "< i am married and and have two two two sons\n",
      "\n",
      "> han on luultavasti kuollut .\n",
      "= he is probably dead .\n",
      "< she is the . . . <EOS>\n",
      "\n",
      "> han on bussikuski .\n",
      "= he is a bus driver .\n",
      "< she is a kind person . <EOS>\n",
      "\n",
      "> sinut on saarrettu .\n",
      "= you re surrounded .\n",
      "< i m really busy . <EOS>\n",
      "\n",
      "> olen kurkkuani myoten taynna ranskaa .\n",
      "= i m sick of french .\n",
      "< i m quite in french french . <EOS>\n",
      "\n",
      "> en mene kokoukseen .\n",
      "= i m not going to the meeting .\n",
      "< i m not to that . <EOS>\n",
      "\n",
      "> han on menestyksekas pankkiiri .\n",
      "= he s a successful banker .\n",
      "< she is a kind . . <EOS>\n",
      "\n",
      "> miten ilahduttavaa tehda tuttavuutta kanssanne .\n",
      "= i m delighted to make your acquaintance .\n",
      "< i m trying to hang out with . <EOS>\n",
      "\n",
      "> olet televisiossa .\n",
      "= you re on television .\n",
      "< you re a . <EOS>\n",
      "\n",
      "> olen uuvuksissa .\n",
      "= i m exhausted .\n",
      "< i m a . . . <EOS>\n",
      "\n",
      "> odotan innolla saavani sinulta kirjeen .\n",
      "= i m looking forward to getting your letter .\n",
      "< i m looking for my . . <EOS>\n",
      "\n",
      "> sina olet tyhma .\n",
      "= you are stupid .\n",
      "< you are stupid . <EOS>\n",
      "\n",
      "> olen iloinen siita etta me loysimme teidat .\n",
      "= i m glad we found you .\n",
      "< i m glad that we ll . <EOS>\n",
      "\n",
      "> han on hanen ystavansa .\n",
      "= he s her friend .\n",
      "< she is a kind . <EOS>\n",
      "\n",
      "> tomi sulla on yllasi mun paita .\n",
      "= you re wearing my shirt tom .\n",
      "< we re sorry for my . . <EOS>\n",
      "\n",
      "> olen koditon .\n",
      "= i m homeless .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> han on hanta viisi vuotta nuorempi .\n",
      "= she s five years younger than he is .\n",
      "< she is a little than than . <EOS>\n",
      "\n",
      "> lahdemme huomenna .\n",
      "= we re going to leave tomorrow .\n",
      "< we re going to . . <EOS>\n",
      "\n",
      "> osallistun ranskan kurssille tana lukukautena .\n",
      "= i m taking french this semester .\n",
      "< i m used to it the . <EOS>\n",
      "\n",
      "> mina olen sanaton .\n",
      "= i m at a loss for words .\n",
      "< i m in the . <EOS>\n",
      "\n",
      "> olen tosi lihava .\n",
      "= i m extremely fat .\n",
      "< i m very tired . <EOS>\n",
      "\n",
      "> han on vanha .\n",
      "= he is old .\n",
      "< she is a . . <EOS>\n",
      "\n",
      "> olen kyllastynyt valittamiseesi .\n",
      "= i m sick of your complaints .\n",
      "< i m used to the . . <EOS>\n",
      "\n",
      "> sina olet vaarassa .\n",
      "= you re wrong .\n",
      "< you are stupid . <EOS>\n",
      "\n",
      "> han on juoksija .\n",
      "= she is a runner .\n",
      "< she is a . <EOS>\n",
      "\n",
      "> olen syypaa .\n",
      "= i am to blame .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> olet teeskentelija .\n",
      "= you re a hypocrite .\n",
      "< you re a professor . <EOS>\n",
      "\n",
      "> kokeilemme kokonaan uutta menetelmaa .\n",
      "= we are trying a completely new method .\n",
      "< we re trying to hang out with . <EOS>\n",
      "\n",
      "> olet tyhma .\n",
      "= you re stupid .\n",
      "< you are stupid . <EOS>\n",
      "\n",
      "> olet paljon fiksumpi kuin luulet .\n",
      "= you re a lot smarter than you think .\n",
      "< you are a little than you . <EOS>\n",
      "\n",
      "> en ole ilkea .\n",
      "= i m not mean .\n",
      "< i m not sure . <EOS>\n",
      "\n",
      "> he ovat pienia .\n",
      "= they re small .\n",
      "< they re friends . <EOS>\n",
      "\n",
      "> opiskelen ranskan kielioppia .\n",
      "= i m studying french grammar .\n",
      "< i m used to the . <EOS>\n",
      "\n",
      "> odotamme tomia .\n",
      "= we re waiting tom .\n",
      "< we re looking for tom . <EOS>\n",
      "\n",
      "> minua janottaa .\n",
      "= i m thirsty .\n",
      "< i m a little . <EOS>\n",
      "\n",
      "> olen jousimies .\n",
      "= i m a sagittarius .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> olen paassyt taysin yli tomista .\n",
      "= i m totally over tom .\n",
      "< i m really to that . <EOS>\n",
      "\n",
      "> olen lomalla .\n",
      "= i m on vacation .\n",
      "< i m really sure . <EOS>\n",
      "\n",
      "> olen hyvin vasynyt .\n",
      "= i am very tired .\n",
      "< i m very tired . <EOS>\n",
      "\n",
      "> olen yksityisetsiva .\n",
      "= i m a detective .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> opiskelen ranskaa .\n",
      "= i m studying french .\n",
      "< i m studying french . <EOS>\n",
      "\n",
      "> mina vain arvailen .\n",
      "= i m just guessing .\n",
      "< i m sorry to the you . <EOS>\n",
      "\n",
      "> olen koukussa .\n",
      "= i m addicted .\n",
      "< i m sorry . <EOS>\n",
      "\n",
      "> olen vain viaton ohikulkija .\n",
      "= i m just an innocent bystander .\n",
      "< i m sorry to see tom . <EOS>\n",
      "\n",
      "> olet ihan niin kuin mina .\n",
      "= you re just like me .\n",
      "< you are a like me . <EOS>\n",
      "\n",
      "> he ovat taalla .\n",
      "= they re here .\n",
      "< they re here . <EOS>\n",
      "\n",
      "> he ovat professoreja .\n",
      "= they are professors .\n",
      "< they re a . . <EOS>\n",
      "\n",
      "> minua alkaa vasyttaa .\n",
      "= i m beginning to get tired .\n",
      "< i m sorry to the . . <EOS>\n",
      "\n",
      "> olen tottunut tahan .\n",
      "= i m accustomed to this .\n",
      "< i m used to . . <EOS>\n",
      "\n",
      "> olemme onnellisia .\n",
      "= we are happy .\n",
      "< we re having . <EOS>\n",
      "\n",
      "> olen nikkaroimassa linnunponttoa .\n",
      "= i m building a birdhouse .\n",
      "< i m used to a . . <EOS>\n",
      "\n",
      "> olen ihan auki .\n",
      "= i m broke .\n",
      "< i m very tired . <EOS>\n",
      "\n",
      "> sina olet todella herkkatunteinen .\n",
      "= you re very emotional .\n",
      "< you are a very . . <EOS>\n",
      "\n",
      "> han on komea mies .\n",
      "= he is a handsome man .\n",
      "< she s a man man . <EOS>\n",
      "\n",
      "> sina parjaat paremmin ilman tomia .\n",
      "= you re better off without tom .\n",
      "< you re fun off without tom . <EOS>\n",
      "\n",
      "> olen yleensa kotona maanantaisin .\n",
      "= i m usually home on mondays .\n",
      "< i m sorry for you . <EOS>\n",
      "\n",
      "> olen hengenpelastaja .\n",
      "= i m a lifeguard .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> odotan tyttoystavaani .\n",
      "= i m waiting for my girlfriend .\n",
      "< i m looking for my . <EOS>\n",
      "\n",
      "> han pelaa vaarallista pelia .\n",
      "= he s playing a dangerous game .\n",
      "< he is not a . . . <EOS>\n",
      "\n",
      "> olet tosi ihana .\n",
      "= you re very sweet .\n",
      "< you are really really . <EOS>\n",
      "\n",
      "> olemme valmiita talta illalta .\n",
      "= we re done for the night .\n",
      "< we re having to the . . <EOS>\n",
      "\n",
      "> han valittaa jatkuvasti .\n",
      "= he is always complaining .\n",
      "< he is always the . . . <EOS>\n",
      "\n",
      "> valitettavasti ei .\n",
      "= i m afraid not .\n",
      "< i m not a you . <EOS>\n",
      "\n",
      "> olen vapaa .\n",
      "= i m single .\n",
      "< i m on . <EOS>\n",
      "\n",
      "> otat kritiikin liian tosissasi .\n",
      "= you are too sensitive to criticism .\n",
      "< i m going to hang out with . <EOS>\n",
      "\n",
      "> olemme yhdessa kiinni tassa asiassa eiko niin ?\n",
      "= we re in this thing together right ?\n",
      "< we re all to the . . <EOS>\n",
      "\n",
      "> han on astronomian asiantuntija .\n",
      "= he is an expert in astronomy .\n",
      "< he is the a . . . <EOS>\n",
      "\n",
      "> olet vatys .\n",
      "= you re a slob .\n",
      "< you re a . <EOS>\n",
      "\n",
      "> ma hapean mun menneisyytta .\n",
      "= i m ashamed of my past .\n",
      "< i m going to the . . <EOS>\n",
      "\n",
      "> olen sarjakuvapiirtaja .\n",
      "= i m a cartoonist .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> aiomme ostaa auton .\n",
      "= we re going to buy ourselves a car .\n",
      "< we re trying to hang out . <EOS>\n",
      "\n",
      "> olen paassyt taysin yli tomista .\n",
      "= i m totally over tom .\n",
      "< i m really to it . <EOS>\n",
      "\n",
      "> en ole pelkuri .\n",
      "= i m not a coward .\n",
      "< i m not a . . . <EOS>\n",
      "\n",
      "> kotona ollaan !\n",
      "= i m home .\n",
      "< i m here . <EOS>\n",
      "\n",
      "> soitan matkapuhelimesta .\n",
      "= i m calling from a cell phone .\n",
      "< i m going to the you . <EOS>\n",
      "\n",
      "> han on kiltti ihminen .\n",
      "= he is kind .\n",
      "< she is a kind person . <EOS>\n",
      "\n",
      "> olen hyva siina mita teen .\n",
      "= i m good at what i do .\n",
      "< i m very grateful for what you . <EOS>\n",
      "\n",
      "> en ole varma siita etta onko tama oikein .\n",
      "= i m not sure if this is correct .\n",
      "< i m not sure that that that is not sure\n",
      "\n",
      "> olen allerginen kissoille .\n",
      "= i m allergic to cats .\n",
      "< i m used to the . <EOS>\n",
      "\n",
      "> olet vatys .\n",
      "= you re a slob .\n",
      "< you re a . <EOS>\n",
      "\n",
      "> olet hyvassa kunnossa .\n",
      "= you re in fine shape .\n",
      "< i m very tired . <EOS>\n",
      "\n",
      "> he ovat molemmat naimattomia .\n",
      "= they re both unmarried .\n",
      "< they re best . . <EOS>\n",
      "\n",
      "> sina se opettaja olet .\n",
      "= you re the teacher .\n",
      "< you re a professor . <EOS>\n",
      "\n",
      "> vasyttaa !\n",
      "= i m sleepy .\n",
      "< i m drunk . <EOS>\n",
      "\n",
      "> he katsovat elokuvaa .\n",
      "= they are watching a movie .\n",
      "< they re still . . <EOS>\n",
      "\n",
      "> he ovat hyvia ihmisia .\n",
      "= they re good people .\n",
      "< they re a kind . <EOS>\n",
      "\n",
      "> en ole turisti .\n",
      "= i m not a tourist .\n",
      "< i m not a at . <EOS>\n",
      "\n",
      "> mina yritan pitaa tuomon elossa .\n",
      "= i m trying to keep tom alive .\n",
      "< i m trying to keep tom alive . <EOS>\n",
      "\n",
      "> sina olet hyva mies .\n",
      "= you re a good man .\n",
      "< you are a good man . <EOS>\n",
      "\n",
      "> seurustelemme .\n",
      "= we re dating .\n",
      "< you re fun to hang out . <EOS>\n",
      "\n",
      "> olette kaunis .\n",
      "= you are beautiful .\n",
      "< you are a professor . <EOS>\n",
      "\n",
      "> minulla ei ole sunnuntaisin aina vapaata .\n",
      "= i m not always free on sundays .\n",
      "< i m not sure on sundays . <EOS>\n",
      "\n",
      "> han katsoo sinua .\n",
      "= he s looking at you .\n",
      "< he s looking for you . <EOS>\n",
      "\n",
      "> han on nyt puhelimessa .\n",
      "= he s now on the phone .\n",
      "< she is the the . . <EOS>\n",
      "\n",
      "> me kaikki tulemme kuolemaan .\n",
      "= we re all going to die .\n",
      "< we re all on the . . <EOS>\n",
      "\n",
      "> ollaan seinanaapureita .\n",
      "= we re next door neighbors .\n",
      "< we re looking for your . <EOS>\n",
      "\n",
      "> he ovat taalla .\n",
      "= they re here .\n",
      "< they re here . <EOS>\n",
      "\n",
      "> olemme ystaviasi .\n",
      "= we re your friends .\n",
      "< we re having . <EOS>\n",
      "\n",
      "> he ovat yrittamassa .\n",
      "= they re trying .\n",
      "< they re friends . <EOS>\n",
      "\n",
      "> mina olen pidempi kuin sina .\n",
      "= i m taller than you .\n",
      "< i m very tired you . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 38s (- 392m 58s) (500 0%) 3.4914\n",
      "500 lauseen BagOfWords tarkkuus: 2.88363\n",
      "3m 41s (- 273m 43s) (1000 1%) 3.2367\n",
      "500 lauseen BagOfWords tarkkuus: 17.82716\n",
      "4m 43s (- 231m 34s) (1500 2%) 3.0054\n",
      "500 lauseen BagOfWords tarkkuus: 18.90339\n",
      "5m 49s (- 212m 41s) (2000 2%) 2.8289\n",
      "500 lauseen BagOfWords tarkkuus: 22.2907\n",
      "7m 5s (- 205m 27s) (2500 3%) 2.7336\n",
      "500 lauseen BagOfWords tarkkuus: 22.20439\n",
      "7m 42s (- 184m 52s) (3000 4%) 2.6719\n",
      "500 lauseen BagOfWords tarkkuus: 24.03101\n",
      "8m 43s (- 178m 17s) (3500 4%) 2.6778\n",
      "500 lauseen BagOfWords tarkkuus: 26.45875\n",
      "9m 51s (- 174m 59s) (4000 5%) 2.5540\n",
      "500 lauseen BagOfWords tarkkuus: 26.86722\n",
      "10m 57s (- 171m 33s) (4500 6%) 2.5223\n",
      "500 lauseen BagOfWords tarkkuus: 27.46667\n",
      "12m 19s (- 172m 39s) (5000 6%) 2.4964\n",
      "500 lauseen BagOfWords tarkkuus: 27.56072\n",
      "13m 37s (- 172m 13s) (5500 7%) 2.5121\n",
      "500 lauseen BagOfWords tarkkuus: 32.06861\n",
      "14m 44s (- 169m 30s) (6000 8%) 2.3873\n",
      "500 lauseen BagOfWords tarkkuus: 30.35903\n",
      "15m 54s (- 167m 42s) (6500 8%) 2.3616\n",
      "500 lauseen BagOfWords tarkkuus: 33.08119\n",
      "17m 11s (- 167m 4s) (7000 9%) 2.3175\n",
      "500 lauseen BagOfWords tarkkuus: 37.44406\n",
      "18m 22s (- 165m 26s) (7500 10%) 2.1927\n",
      "500 lauseen BagOfWords tarkkuus: 33.03191\n",
      "19m 42s (- 165m 3s) (8000 10%) 2.1701\n",
      "500 lauseen BagOfWords tarkkuus: 37.59513\n",
      "20m 57s (- 164m 0s) (8500 11%) 2.1838\n",
      "500 lauseen BagOfWords tarkkuus: 37.19353\n",
      "22m 4s (- 161m 53s) (9000 12%) 2.0808\n",
      "500 lauseen BagOfWords tarkkuus: 39.93949\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-2cbf331e8802>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-161-1abd3cedad1a>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 19\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-77785d753587>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Attention\n",
    "---------------------\n",
    "\n",
    "A useful property of the attention mechanism is its highly interpretable\n",
    "outputs. Because it is used to weight specific encoder outputs of the\n",
    "input sequence, we can imagine looking where the network is focused most\n",
    "at each time step.\n",
    "\n",
    "You could simply run ``plt.matshow(attentions)`` to see attention output\n",
    "displayed as a matrix, with the columns being input steps and rows being\n",
    "output steps:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3036e5e650>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better viewing experience we will do the extra work of adding axes\n",
    "and labels:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = elle a cinq ans de moins que moi .\n",
      "output = she is afraid of my . . <EOS>\n",
      "input = elle est trop petit .\n",
      "output = she is a of . . <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = je ne crains pas de mourir .\n",
      "output = i m not of i . . . <EOS>\n",
      "input = c est un jeune directeur plein de talent .\n",
      "output = he s a of the . <EOS>\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises\n",
    "=========\n",
    "\n",
    "-  Try with a different dataset\n",
    "\n",
    "   -  Another language pair\n",
    "   -  Human → Machine (e.g. IOT commands)\n",
    "   -  Chat → Response\n",
    "   -  Question → Answer\n",
    "\n",
    "-  Replace the embeddings with pre-trained word embeddings such as word2vec or\n",
    "   GloVe\n",
    "-  Try with more layers, more hidden units, and more sentences. Compare\n",
    "   the training time and results.\n",
    "-  If you use a translation file where pairs have two of the same phrase\n",
    "   (``I am test \\t I am test``), you can use this as an autoencoder. Try\n",
    "   this:\n",
    "\n",
    "   -  Train as an autoencoder\n",
    "   -  Save only the Encoder network\n",
    "   -  Train a new Decoder for translation from there\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
